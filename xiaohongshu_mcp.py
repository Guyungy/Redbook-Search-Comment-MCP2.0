from typing import Any, List, Dict, Optional
import asyncio
import json
import os
import pandas as pd
from datetime import datetime
from playwright.async_api import async_playwright
from fastmcp import FastMCP

# è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶Playwrightä½¿ç”¨è‹±æ–‡è·¯å¾„çš„ä¸´æ—¶ç›®å½•ï¼ˆå¿…é¡»åœ¨å¯¼å…¥playwrightä¹‹å‰è®¾ç½®ï¼‰
import sys
import subprocess

# å¼ºåˆ¶è®¾ç½®ç³»ç»Ÿçº§ç¯å¢ƒå˜é‡
os.environ['TMPDIR'] = 'C:\\temp_playwright'
os.environ['TMP'] = 'C:\\temp_playwright'
os.environ['TEMP'] = 'C:\\temp_playwright'
os.environ['PLAYWRIGHT_BROWSERS_PATH'] = 'C:\\playwright_browsers'

# è®¾ç½®Windowsç³»ç»Ÿç¯å¢ƒå˜é‡ï¼ˆç”¨æˆ·çº§åˆ«ï¼‰
try:
    subprocess.run(['setx', 'TEMP', 'C:\\temp_playwright'], check=False, capture_output=True)
    subprocess.run(['setx', 'TMP', 'C:\\temp_playwright'], check=False, capture_output=True)
except Exception:
    pass  # å¿½ç•¥è®¾ç½®å¤±è´¥

# åˆå§‹åŒ– FastMCP æœåŠ¡å™¨
mcp = FastMCP("xiaohongshu_scraper")

# å…¨å±€å˜é‡ - ä½¿ç”¨è‹±æ–‡ç»å¯¹è·¯å¾„é¿å…ä¸­æ–‡è·¯å¾„æƒé™é—®é¢˜
BROWSER_DATA_DIR = "C:\\browser_data"
DATA_DIR = "C:\\redbook_data"
TEMP_PLAYWRIGHT_DIR = "C:\\temp_playwright"
PLAYWRIGHT_BROWSERS_DIR = "C:\\playwright_browsers"
TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(BROWSER_DATA_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TEMP_PLAYWRIGHT_DIR, exist_ok=True)
os.makedirs(PLAYWRIGHT_BROWSERS_DIR, exist_ok=True)

# ç”¨äºå­˜å‚¨æµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼Œä»¥ä¾¿åœ¨ä¸åŒæ–¹æ³•ä¹‹é—´å…±äº«
browser_context = None
main_page = None
is_logged_in = False

def process_url(url: str) -> str:
    """å¤„ç†URLï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®å¹¶ä¿ç•™æ‰€æœ‰å‚æ•°
    
    Args:
        url: åŸå§‹URL
    
    Returns:
        str: å¤„ç†åçš„URL
    """
    processed_url = url.strip()
    
    # ç§»é™¤å¯èƒ½çš„@ç¬¦å·å‰ç¼€
    if processed_url.startswith('@'):
        processed_url = processed_url[1:]
    
    # ç¡®ä¿URLä½¿ç”¨httpsåè®®
    if processed_url.startswith('http://'):
        processed_url = 'https://' + processed_url[7:]
    elif not processed_url.startswith('https://'):
        processed_url = 'https://' + processed_url
        
    # å¦‚æœURLä¸åŒ…å«www.xiaohongshu.comï¼Œåˆ™æ·»åŠ å®ƒ
    if 'xiaohongshu.com' in processed_url and 'www.xiaohongshu.com' not in processed_url:
        processed_url = processed_url.replace('xiaohongshu.com', 'www.xiaohongshu.com')
    
    return processed_url

async def ensure_browser():
    """ç¡®ä¿æµè§ˆå™¨å·²å¯åŠ¨å¹¶ç™»å½•"""
    global browser_context, main_page, is_logged_in
    
    if browser_context is None:
        # å¼ºåˆ¶è®¾ç½®å½“å‰è¿›ç¨‹çš„ç¯å¢ƒå˜é‡
        import tempfile
        import shutil
        
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ä¸´æ—¶æ–‡ä»¶
        try:
            temp_dirs = [TEMP_PLAYWRIGHT_DIR, os.path.join(os.environ.get('TEMP', ''), 'playwright-artifacts*')]
            for temp_pattern in temp_dirs:
                if '*' in temp_pattern:
                    import glob
                    for path in glob.glob(temp_pattern):
                        if os.path.exists(path):
                            shutil.rmtree(path, ignore_errors=True)
                elif os.path.exists(temp_pattern):
                    shutil.rmtree(temp_pattern, ignore_errors=True)
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        # é‡æ–°åˆ›å»ºä¸´æ—¶ç›®å½•
        os.makedirs(TEMP_PLAYWRIGHT_DIR, exist_ok=True)
        
        # å¼ºåˆ¶ä¿®æ”¹å½“å‰è¿›ç¨‹ç¯å¢ƒå˜é‡
        os.environ['TMPDIR'] = TEMP_PLAYWRIGHT_DIR
        os.environ['TMP'] = TEMP_PLAYWRIGHT_DIR
        os.environ['TEMP'] = TEMP_PLAYWRIGHT_DIR
        os.environ['PLAYWRIGHT_BROWSERS_PATH'] = PLAYWRIGHT_BROWSERS_DIR
        
        # è®¾ç½®tempfileæ¨¡å—çš„ä¸´æ—¶ç›®å½•
        tempfile.tempdir = TEMP_PLAYWRIGHT_DIR
        
        # å¯åŠ¨æµè§ˆå™¨
        playwright_instance = await async_playwright().start()
        
        # ä½¿ç”¨æŒä¹…åŒ–ä¸Šä¸‹æ–‡æ¥ä¿å­˜ç”¨æˆ·çŠ¶æ€
        browser_context = await playwright_instance.chromium.launch_persistent_context(
            user_data_dir=BROWSER_DATA_DIR,
            headless=False,  # ééšè—æ¨¡å¼ï¼Œæ–¹ä¾¿ç”¨æˆ·ç™»å½•
            viewport={"width": 1280, "height": 800},
            timeout=60000,
            env={
                **os.environ,
                'TMPDIR': TEMP_PLAYWRIGHT_DIR,
                'TMP': TEMP_PLAYWRIGHT_DIR,
                'TEMP': TEMP_PLAYWRIGHT_DIR,
                'PLAYWRIGHT_BROWSERS_PATH': PLAYWRIGHT_BROWSERS_DIR
            }
        )
        
        # åˆ›å»ºä¸€ä¸ªæ–°é¡µé¢
        if browser_context.pages:
            main_page = browser_context.pages[0]
        else:
            main_page = await browser_context.new_page()
        
        # è®¾ç½®é¡µé¢çº§åˆ«çš„è¶…æ—¶æ—¶é—´
        main_page.set_default_timeout(60000)
    
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    if not is_logged_in:
        # è®¿é—®å°çº¢ä¹¦é¦–é¡µ
        if main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
            await main_page.goto("https://www.xiaohongshu.com", timeout=60000)
            await asyncio.sleep(3)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
            login_elements = await main_page.query_selector_all('text="ç™»å½•"') if main_page else []  # æ·»åŠ ç©ºæ£€æŸ¥
            if login_elements:
                return False  # éœ€è¦ç™»å½•
            else:
                is_logged_in = True
                return True  # å·²ç™»å½•
        else:
            return False  # main_pageä¸ºNoneï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–
    
    return True

@mcp.tool()
async def login() -> str:
    """ç™»å½•å°çº¢ä¹¦è´¦å·"""
    global is_logged_in
    
    await ensure_browser()
    
    if is_logged_in:
        return "å·²ç™»å½•å°çº¢ä¹¦è´¦å·"
    
    # è®¿é—®å°çº¢ä¹¦ç™»å½•é¡µé¢
    if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
        return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
        
    await main_page.goto("https://www.xiaohongshu.com", timeout=60000)
    await asyncio.sleep(3)
    
    # æŸ¥æ‰¾ç™»å½•æŒ‰é’®å¹¶ç‚¹å‡»
    login_elements = await main_page.query_selector_all('text="ç™»å½•"') if main_page else []  # æ·»åŠ ç©ºæ£€æŸ¥
    if login_elements:
        await login_elements[0].click()
        
        # æç¤ºç”¨æˆ·æ‰‹åŠ¨ç™»å½•
        message = "è¯·åœ¨æ‰“å¼€çš„æµè§ˆå™¨çª—å£ä¸­å®Œæˆç™»å½•æ“ä½œã€‚ç™»å½•æˆåŠŸåï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ç»§ç»­ã€‚"
        
        # ç­‰å¾…ç”¨æˆ·ç™»å½•æˆåŠŸ
        max_wait_time = 180  # ç­‰å¾…3åˆ†é’Ÿ
        wait_interval = 5
        waited_time = 0
        
        while waited_time < max_wait_time:
            # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•æˆåŠŸ
            if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                
            still_login = await main_page.query_selector_all('text="ç™»å½•"')
            if not still_login:
                is_logged_in = True
                await asyncio.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½
                return "ç™»å½•æˆåŠŸï¼"
            
            # ç»§ç»­ç­‰å¾…
            await asyncio.sleep(wait_interval)
            waited_time += wait_interval
        
        return "ç™»å½•ç­‰å¾…è¶…æ—¶ã€‚è¯·é‡è¯•æˆ–æ‰‹åŠ¨ç™»å½•åå†ä½¿ç”¨å…¶ä»–åŠŸèƒ½ã€‚"
    else:
        is_logged_in = True
        return "å·²ç™»å½•å°çº¢ä¹¦è´¦å·"

@mcp.tool()
async def search_notes(keywords: str, limit: int = 5) -> str:
    """æ ¹æ®å…³é”®è¯æœç´¢ç¬”è®°ï¼ˆåŸºç¡€æœç´¢ï¼‰
    
    Args:
        keywords: æœç´¢å…³é”®è¯
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
    """
    return await _basic_search(keywords, limit)

@mcp.tool()
async def smart_search_notes(task_description: str, limit: int = 10) -> str:
    """æ™ºèƒ½æœç´¢ç¬”è®° - AI Agentå¼æ·±åº¦æœç´¢
    
    è¿™æ˜¯ä¸€ä¸ªæ™ºèƒ½æœç´¢ç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š
    1. åˆ†æç”¨æˆ·ä»»åŠ¡æ„å›¾
    2. è‡ªåŠ¨ç”Ÿæˆå¤šä¸ªæœç´¢ç­–ç•¥
    3. æ‰§è¡Œå¤šè½®æœç´¢å¹¶ä¼˜åŒ–å…³é”®è¯
    4. æ™ºèƒ½ç­›é€‰å’Œæ’åºç»“æœ
    5. æä¾›æœç´¢åˆ†ææŠ¥å‘Š
    
    Args:
        task_description: ä»»åŠ¡æè¿°ï¼Œä¾‹å¦‚ï¼š
                         "æˆ‘æƒ³æ‰¾ä¸€äº›å…³äºæŠ¤è‚¤çš„ç¬”è®°ï¼Œç‰¹åˆ«æ˜¯æ•æ„Ÿè‚ŒæŠ¤ç†æ–¹é¢çš„"
                         "å¸®æˆ‘æœç´¢æœ€è¿‘æµè¡Œçš„ç©¿æ­è¶‹åŠ¿ï¼Œåå‘æ—¥ç³»é£æ ¼"
                         "æ‰¾ä¸€äº›å…³äºAIå·¥å…·ä½¿ç”¨çš„æ•™ç¨‹å’Œç»éªŒåˆ†äº«"
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
    
    Returns:
        str: åŒ…å«æœç´¢ç»“æœå’Œåˆ†ææŠ¥å‘Šçš„è¯¦ç»†ä¿¡æ¯
    """
    return await _intelligent_search_agent(task_description, limit)

async def _basic_search(keywords: str, limit: int = 5) -> str:
    """åŸºç¡€æœç´¢åŠŸèƒ½ï¼ˆåŸsearch_notesé€»è¾‘ï¼‰"""
    login_status = await ensure_browser()
    if not login_status:
        return "è¯·å…ˆç™»å½•å°çº¢ä¹¦è´¦å·"
    
    if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
        return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
        
    # æ„å»ºæœç´¢URLå¹¶è®¿é—®
    search_url = f"https://www.xiaohongshu.com/search_result?keyword={keywords}"
    try:
        await main_page.goto(search_url, timeout=60000)
        await asyncio.sleep(5)  # ç­‰å¾…é¡µé¢åŠ è½½
        
        # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
        await asyncio.sleep(5)
        
        # æ‰“å°é¡µé¢HTMLç”¨äºè°ƒè¯•
        page_html = await main_page.content()
        print(f"é¡µé¢HTMLç‰‡æ®µ: {page_html[10000:10500]}...")
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„é€‰æ‹©å™¨è·å–å¸–å­å¡ç‰‡
        print("å°è¯•è·å–å¸–å­å¡ç‰‡...")
        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
            return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
            
        post_cards = await main_page.query_selector_all('section.note-item')
        print(f"æ‰¾åˆ° {len(post_cards)} ä¸ªå¸–å­å¡ç‰‡")
        
        if not post_cards:
            # å°è¯•å¤‡ç”¨é€‰æ‹©å™¨
            if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                
            post_cards = await main_page.query_selector_all('div[data-v-a264b01a]')
            print(f"ä½¿ç”¨å¤‡ç”¨é€‰æ‹©å™¨æ‰¾åˆ° {len(post_cards)} ä¸ªå¸–å­å¡ç‰‡")
        
        post_links = []
        post_titles = []
        
        for card in post_cards:
            try:
                # è·å–é“¾æ¥
                link_element = await card.query_selector('a[href*="/search_result/"]') if card else None  # æ·»åŠ ç©ºæ£€æŸ¥
                if not link_element:
                    continue
                
                href = await link_element.get_attribute('href')
                if href and '/search_result/' in href:
                    # æ„å»ºå®Œæ•´URL
                    if href.startswith('/'):
                        full_url = f"https://www.xiaohongshu.com{href}"
                    else:
                        full_url = href
                        
                    post_links.append(full_url)
                    
                    # å°è¯•è·å–å¸–å­æ ‡é¢˜
                    try:
                        # æ‰“å°å¡ç‰‡HTMLç”¨äºè°ƒè¯•
                        card_html = await card.inner_html() if card else ""  # æ·»åŠ ç©ºæ£€æŸ¥
                        print(f"å¡ç‰‡HTMLç‰‡æ®µ: {card_html[:200]}...")
                        
                        # é¦–å…ˆå°è¯•è·å–å¡ç‰‡å†…çš„footerä¸­çš„æ ‡é¢˜
                        title_element = await card.query_selector('div.footer a.title span') if card else None  # æ·»åŠ ç©ºæ£€æŸ¥
                        if title_element:
                            title = await title_element.text_content() 
                            print(f"æ‰¾åˆ°æ ‡é¢˜(æ–¹æ³•1): {title}")
                        else:
                            # å°è¯•ç›´æ¥è·å–æ ‡é¢˜å…ƒç´ 
                            title_element = await card.query_selector('a.title span') if card else None  # æ·»åŠ ç©ºæ£€æŸ¥
                            if title_element:
                                title = await title_element.text_content()
                                print(f"æ‰¾åˆ°æ ‡é¢˜(æ–¹æ³•2): {title}")
                            else:
                                # å°è¯•è·å–ä»»ä½•å¯èƒ½çš„æ–‡æœ¬å†…å®¹
                                text_elements = await card.query_selector_all('span') if card else []  # æ·»åŠ ç©ºæ£€æŸ¥
                                potential_titles = []
                                for text_el in text_elements:
                                    text = await text_el.text_content() if text_el else ""  # æ·»åŠ ç©ºæ£€æŸ¥
                                    if text and len(text.strip()) > 5:
                                        potential_titles.append(text.strip())
                                
                                if potential_titles:
                                    # é€‰æ‹©æœ€é•¿çš„æ–‡æœ¬ä½œä¸ºæ ‡é¢˜
                                    title = max(potential_titles, key=len) if potential_titles else "æœªçŸ¥æ ‡é¢˜"  # æ·»åŠ ç©ºæ£€æŸ¥
                                    print(f"æ‰¾åˆ°å¯èƒ½çš„æ ‡é¢˜(æ–¹æ³•3): {title}")
                                else:
                                    # å°è¯•ç›´æ¥è·å–å¡ç‰‡ä¸­çš„æ‰€æœ‰æ–‡æœ¬
                                    if not card:  # æ·»åŠ ç©ºæ£€æŸ¥
                                        title = "æœªçŸ¥æ ‡é¢˜"
                                        print("å¡ç‰‡ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼'æœªçŸ¥æ ‡é¢˜'")
                                    else:
                                        all_text = await card.evaluate('el => Array.from(el.querySelectorAll("*")).map(node => node.textContent).filter(text => text && text.trim().length > 5)')
                                        if all_text and isinstance(all_text, list) and all_text:  # ä½¿ç”¨å¸ƒå°”æ£€æŸ¥æ›¿ä»£len
                                            # é€‰æ‹©æœ€é•¿çš„æ–‡æœ¬ä½œä¸ºæ ‡é¢˜
                                            title = max(all_text, key=len)
                                            print(f"æ‰¾åˆ°å¯èƒ½çš„æ ‡é¢˜(æ–¹æ³•4): {title}")
                                        else:
                                            title = "æœªçŸ¥æ ‡é¢˜"
                                            print("æ— æ³•æ‰¾åˆ°æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤å€¼'æœªçŸ¥æ ‡é¢˜'")
                        
                        # å¦‚æœè·å–åˆ°çš„æ ‡é¢˜ä¸ºç©ºï¼Œè®¾ä¸ºæœªçŸ¥æ ‡é¢˜
                        if not title or (isinstance(title, str) and title.strip() == ""):  # å¢åŠ ç±»å‹æ£€æŸ¥
                            title = "æœªçŸ¥æ ‡é¢˜"
                            print("è·å–åˆ°çš„æ ‡é¢˜ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å€¼'æœªçŸ¥æ ‡é¢˜'")
                    except Exception as e:
                        print(f"è·å–æ ‡é¢˜æ—¶å‡ºé”™: {str(e)}")
                        title = "æœªçŸ¥æ ‡é¢˜"
                    
                    post_titles.append(title)
            except Exception as e:
                print(f"å¤„ç†å¸–å­å¡ç‰‡æ—¶å‡ºé”™: {str(e)}")
        
        # å»é‡
        unique_posts = []
        seen_urls = set()
        for url, title in zip(post_links, post_titles):
            if url not in seen_urls:
                seen_urls.add(url)
                unique_posts.append({"url": url, "title": title})
        
        # é™åˆ¶è¿”å›æ•°é‡
        unique_posts = unique_posts[:limit]
        
        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        if unique_posts:
            result = "æœç´¢ç»“æœï¼š\n\n"
            for i, post in enumerate(unique_posts, 1):
                result += f"{i}. {post['title']}\n   é“¾æ¥: {post['url']}\n\n"
            
            return result
        else:
            return f"æœªæ‰¾åˆ°ä¸\"{keywords}\"ç›¸å…³çš„ç¬”è®°"
    
    except Exception as e:
        return f"æœç´¢ç¬”è®°æ—¶å‡ºé”™: {str(e)}"

async def _intelligent_search_agent(task_description: str, limit: int = 10) -> str:
    """æ™ºèƒ½æœç´¢ä»£ç† - å®ç°AI Agentå¼çš„æ·±åº¦æœç´¢"""
    try:
        print(f"\n=== æ™ºèƒ½æœç´¢ä»£ç†å¯åŠ¨ ===")
        print(f"ä»»åŠ¡æè¿°: {task_description}")
        print(f"ç›®æ ‡ç»“æœæ•°é‡: {limit}")
        
        # ç¬¬ä¸€æ­¥ï¼šä»»åŠ¡æ„å›¾åˆ†æ
        search_strategy = await _analyze_search_intent(task_description)
        print(f"\næœç´¢ç­–ç•¥åˆ†æå®Œæˆ:")
        print(f"- ä¸»è¦é¢†åŸŸ: {search_strategy['domain']}")
        print(f"- æ ¸å¿ƒå…³é”®è¯: {search_strategy['core_keywords']}")
        print(f"- æ‰©å±•å…³é”®è¯: {search_strategy['extended_keywords']}")
        print(f"- æœç´¢ä¼˜å…ˆçº§: {search_strategy['priority']}")
        
        # ç¬¬äºŒæ­¥ï¼šå¤šè½®æœç´¢æ‰§è¡Œ
        all_results = []
        search_rounds = []
        
        # æ‰§è¡Œæ ¸å¿ƒå…³é”®è¯æœç´¢
        for i, keyword_group in enumerate(search_strategy['search_queries'][:3]):
            print(f"\n--- ç¬¬{i+1}è½®æœç´¢ ---")
            print(f"æœç´¢å…³é”®è¯: {keyword_group}")
            
            round_results = await _execute_search_round(keyword_group, min(limit, 8))
            search_rounds.append({
                'round': i+1,
                'keywords': keyword_group,
                'results_count': len(round_results),
                'results': round_results
            })
            all_results.extend(round_results)
            
            # é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
            await asyncio.sleep(2)
        
        # ç¬¬ä¸‰æ­¥ï¼šç»“æœå»é‡å’Œæ™ºèƒ½ç­›é€‰
        print(f"\n--- ç»“æœå¤„ç†é˜¶æ®µ ---")
        print(f"åŸå§‹ç»“æœæ•°é‡: {len(all_results)}")
        
        unique_results = await _deduplicate_results(all_results)
        print(f"å»é‡åç»“æœæ•°é‡: {len(unique_results)}")
        
        # ç¬¬å››æ­¥ï¼šæ™ºèƒ½æ’åºå’Œç­›é€‰
        scored_results = await _score_and_rank_results(unique_results, search_strategy, task_description)
        final_results = scored_results[:limit]
        print(f"æœ€ç»ˆç­›é€‰ç»“æœæ•°é‡: {len(final_results)}")
        
        # ç¬¬äº”æ­¥ï¼šç”Ÿæˆæœç´¢æŠ¥å‘Š
        report = await _generate_search_report(task_description, search_strategy, search_rounds, final_results)
        
        return report
        
    except Exception as e:
        return f"æ™ºèƒ½æœç´¢æ—¶å‡ºé”™: {str(e)}"

async def _analyze_search_intent(task_description: str) -> dict:
    """åˆ†ææœç´¢æ„å›¾å¹¶ç”Ÿæˆæœç´¢ç­–ç•¥"""
    # é¢†åŸŸå…³é”®è¯æ˜ å°„
    domain_mapping = {
        "ç¾å¦†": ["æŠ¤è‚¤", "åŒ–å¦†", "å½©å¦†", "ç¾å®¹", "é¢è†œ", "ç²¾å", "ç²‰åº•", "å£çº¢", "çœ¼å½±", "æ•æ„Ÿè‚Œ", "ç—˜ç—˜", "ç¾ç™½", "æŠ—è€"],
        "ç©¿æ­": ["ç©¿æ­", "æ­é…", "æœè£…", "æ—¶å°š", "é£æ ¼", "æ—¥ç³»", "éŸ©ç³»", "æ¬§ç¾", "å¤å¤", "ç®€çº¦", "ç”œç¾", "é…·å¸…", "èŒåœº"],
        "ç¾é£Ÿ": ["ç¾é£Ÿ", "æ–™ç†", "çƒ¹é¥ª", "é£Ÿè°±", "ç”œå“", "çƒ˜ç„™", "å®¶å¸¸èœ", "å‡è„‚é¤", "å¥åº·é¥®é£Ÿ", "ç½‘çº¢åº—"],
        "æ—…è¡Œ": ["æ—…è¡Œ", "æ—…æ¸¸", "æ”»ç•¥", "æ™¯ç‚¹", "æ°‘å®¿", "é…’åº—", "æœºç¥¨", "ç­¾è¯", "è‡ªç”±è¡Œ", "è·Ÿå›¢"],
        "å¥èº«": ["å¥èº«", "è¿åŠ¨", "ç˜¦èº«", "å‡è‚¥", "ç‘œä¼½", "è·‘æ­¥", "åŠ›é‡è®­ç»ƒ", "æœ‰æ°§", "å¡‘å½¢", "é©¬ç”²çº¿"],
        "æ•°ç ": ["æ•°ç ", "æ‰‹æœº", "ç”µè„‘", "ç›¸æœº", "è€³æœº", "æ™ºèƒ½", "ç§‘æŠ€", "è¯„æµ‹", "å¼€ç®±"],
        "å®¶å±…": ["å®¶å±…", "è£…ä¿®", "å®¶å…·", "è®¾è®¡", "æ”¶çº³", "å¸ƒç½®", "è½¯è£…", "åŒ—æ¬§", "ç®€çº¦", "æ¸©é¦¨"],
        "AI": ["AI", "äººå·¥æ™ºèƒ½", "ChatGPT", "Claude", "å¤§æ¨¡å‹", "ç¼–ç¨‹", "å·¥å…·", "æ•ˆç‡", "è‡ªåŠ¨åŒ–"]
    }
    
    # åˆ†æä»»åŠ¡æè¿°ï¼Œè¯†åˆ«é¢†åŸŸå’Œå…³é”®è¯
    detected_domain = "ç”Ÿæ´»"
    core_keywords = []
    extended_keywords = []
    
    task_lower = task_description.lower()
    
    # è¯†åˆ«ä¸»è¦é¢†åŸŸ
    for domain, keywords in domain_mapping.items():
        for keyword in keywords:
            if keyword.lower() in task_lower:
                detected_domain = domain
                core_keywords.append(keyword)
                break
        if detected_domain != "ç”Ÿæ´»":
            break
    
    # å¦‚æœè¯†åˆ«åˆ°é¢†åŸŸï¼Œæ·»åŠ ç›¸å…³æ‰©å±•å…³é”®è¯
    if detected_domain in domain_mapping:
        extended_keywords = domain_mapping[detected_domain][:8]
    
    # ä»ä»»åŠ¡æè¿°ä¸­æå–å…¶ä»–å…³é”®è¯
    import re
    # æå–ä¸­æ–‡è¯æ±‡
    chinese_words = re.findall(r'[\u4e00-\u9fff]+', task_description)
    for word in chinese_words:
        if len(word) >= 2 and word not in core_keywords:
            core_keywords.append(word)
    
    # ç”Ÿæˆæœç´¢æŸ¥è¯¢ç»„åˆ
    search_queries = []
    
    # æ ¸å¿ƒå…³é”®è¯ç»„åˆ
    if core_keywords:
        search_queries.append(" ".join(core_keywords[:3]))
    
    # é¢†åŸŸ+æ ¸å¿ƒè¯ç»„åˆ
    if detected_domain != "ç”Ÿæ´»" and core_keywords:
        search_queries.append(f"{detected_domain} {core_keywords[0]}")
    
    # æ‰©å±•å…³é”®è¯ç»„åˆ
    for ext_keyword in extended_keywords[:3]:
        if core_keywords:
            search_queries.append(f"{ext_keyword} {core_keywords[0]}")
        else:
            search_queries.append(ext_keyword)
    
    return {
        'domain': detected_domain,
        'core_keywords': core_keywords[:5],
        'extended_keywords': extended_keywords,
        'search_queries': search_queries[:5],
        'priority': 'high' if len(core_keywords) > 2 else 'medium'
    }

async def _execute_search_round(keywords: str, limit: int) -> list:
    """æ‰§è¡Œå•è½®æœç´¢"""
    try:
        result_str = await _basic_search(keywords, limit)
        
        # è§£ææœç´¢ç»“æœ
        results = []
        if "æœç´¢ç»“æœï¼š" in result_str:
            lines = result_str.split('\n')
            current_item = {}
            
            for line in lines:
                line = line.strip()
                if line and line[0].isdigit() and '. ' in line:
                    # ä¿å­˜ä¸Šä¸€ä¸ªé¡¹ç›®
                    if current_item:
                        results.append(current_item)
                    # å¼€å§‹æ–°é¡¹ç›®
                    title = line.split('. ', 1)[1] if '. ' in line else line
                    current_item = {'title': title, 'url': '', 'keywords': keywords}
                elif line.startswith('é“¾æ¥: '):
                    if current_item:
                        current_item['url'] = line.replace('é“¾æ¥: ', '')
            
            # æ·»åŠ æœ€åä¸€ä¸ªé¡¹ç›®
            if current_item:
                results.append(current_item)
        
        return results
        
    except Exception as e:
        print(f"æœç´¢è½®æ¬¡æ‰§è¡Œå‡ºé”™: {str(e)}")
        return []

async def _deduplicate_results(results: list) -> list:
    """å»é‡æœç´¢ç»“æœ"""
    seen_urls = set()
    unique_results = []
    
    for result in results:
        url = result.get('url', '')
        if url and url not in seen_urls:
            seen_urls.add(url)
            unique_results.append(result)
    
    return unique_results

async def _score_and_rank_results(results: list, strategy: dict, task_description: str) -> list:
    """å¯¹æœç´¢ç»“æœè¿›è¡Œè¯„åˆ†å’Œæ’åº"""
    scored_results = []
    
    for result in results:
        score = 0
        title = result.get('title', '').lower()
        
        # æ ¸å¿ƒå…³é”®è¯åŒ¹é…å¾—åˆ†
        for keyword in strategy['core_keywords']:
            if keyword.lower() in title:
                score += 10
        
        # é¢†åŸŸå…³é”®è¯åŒ¹é…å¾—åˆ†
        domain_keywords = {
            "ç¾å¦†": ["æŠ¤è‚¤", "åŒ–å¦†", "ç¾å®¹"],
            "ç©¿æ­": ["ç©¿æ­", "æ­é…", "æ—¶å°š"],
            "ç¾é£Ÿ": ["ç¾é£Ÿ", "æ–™ç†", "é£Ÿè°±"],
            "æ—…è¡Œ": ["æ—…è¡Œ", "æ”»ç•¥", "æ™¯ç‚¹"],
            "å¥èº«": ["å¥èº«", "è¿åŠ¨", "å‡è‚¥"],
            "æ•°ç ": ["æ•°ç ", "ç§‘æŠ€", "è¯„æµ‹"],
            "å®¶å±…": ["å®¶å±…", "è£…ä¿®", "è®¾è®¡"],
            "AI": ["AI", "å·¥å…·", "æ•ˆç‡"]
        }
        
        if strategy['domain'] in domain_keywords:
            for keyword in domain_keywords[strategy['domain']]:
                if keyword in title:
                    score += 5
        
        # æ ‡é¢˜é•¿åº¦åˆç†æ€§å¾—åˆ†
        title_len = len(result.get('title', ''))
        if 10 <= title_len <= 50:
            score += 3
        elif title_len > 50:
            score += 1
        
        # æ·»åŠ éšæœºå› å­é¿å…ç»“æœè¿‡äºå›ºåŒ–
        import random
        score += random.uniform(0, 2)
        
        result['score'] = score
        scored_results.append(result)
    
    # æŒ‰å¾—åˆ†æ’åº
    return sorted(scored_results, key=lambda x: x['score'], reverse=True)

async def _generate_search_report(task_description: str, strategy: dict, search_rounds: list, final_results: list) -> str:
    """ç”Ÿæˆæœç´¢åˆ†ææŠ¥å‘Š"""
    report = f"""ğŸ¤– æ™ºèƒ½æœç´¢åˆ†ææŠ¥å‘Š

ğŸ“‹ ä»»åŠ¡æè¿°: {task_description}

ğŸ¯ æœç´¢ç­–ç•¥åˆ†æ:
â€¢ è¯†åˆ«é¢†åŸŸ: {strategy['domain']}
â€¢ æ ¸å¿ƒå…³é”®è¯: {', '.join(strategy['core_keywords'])}
â€¢ æœç´¢ä¼˜å…ˆçº§: {strategy['priority']}

ğŸ” æœç´¢æ‰§è¡Œè¿‡ç¨‹:"""
    
    total_searched = 0
    for round_info in search_rounds:
        report += f"\nâ€¢ ç¬¬{round_info['round']}è½®: \"{round_info['keywords']}\" â†’ {round_info['results_count']}ä¸ªç»“æœ"
        total_searched += round_info['results_count']
    
    report += f"\n\nğŸ“Š æœç´¢ç»Ÿè®¡:\nâ€¢ æ€»æœç´¢ç»“æœ: {total_searched}ä¸ª\nâ€¢ å»é‡åç»“æœ: {len(final_results)}ä¸ª\nâ€¢ æœ€ç»ˆæ¨è: {len(final_results)}ä¸ª\n\nğŸ† æ¨èç»“æœ:\n\n"
    
    for i, result in enumerate(final_results, 1):
        score_stars = "â­" * min(5, int(result.get('score', 0) // 3))
        report += f"{i}. {result['title']} {score_stars}\n   ğŸ”— {result['url']}\n   ğŸ“Š åŒ¹é…åº¦: {result.get('score', 0):.1f}åˆ†\n\n"
    
    if not final_results:
        report += "âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç¬”è®°ï¼Œå»ºè®®ï¼š\nâ€¢ å°è¯•æ›´é€šç”¨çš„å…³é”®è¯\nâ€¢ æ£€æŸ¥å…³é”®è¯æ‹¼å†™\nâ€¢ æ‰©å¤§æœç´¢èŒƒå›´\n"
    
    return report

@mcp.tool()
async def deep_search_and_analyze(task_description: str, analyze_content: bool = True, limit: int = 5) -> str:
    """æ·±åº¦æœç´¢å¹¶åˆ†æ - æœ€é«˜çº§çš„AI Agentæœç´¢æ¨¡å¼
    
    è¿™æ˜¯æœ€æ™ºèƒ½çš„æœç´¢æ¨¡å¼ï¼Œèƒ½å¤Ÿï¼š
    1. æ‰§è¡Œæ™ºèƒ½æœç´¢è·å–ç›¸å…³ç¬”è®°
    2. è‡ªåŠ¨åˆ†ææ¯ä¸ªç¬”è®°çš„è¯¦ç»†å†…å®¹
    3. æå–å…³é”®ä¿¡æ¯å’Œè¶‹åŠ¿
    4. ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š
    5. æä¾›è¡ŒåŠ¨å»ºè®®
    
    Args:
        task_description: ä»»åŠ¡æè¿°
        analyze_content: æ˜¯å¦åˆ†æç¬”è®°å†…å®¹ï¼ˆè€—æ—¶è¾ƒé•¿ä½†ä¿¡æ¯æ›´å…¨é¢ï¼‰
        limit: åˆ†æçš„ç¬”è®°æ•°é‡é™åˆ¶
    
    Returns:
        str: åŒ…å«æœç´¢ç»“æœã€å†…å®¹åˆ†æå’Œè¶‹åŠ¿æŠ¥å‘Šçš„ç»¼åˆä¿¡æ¯
    """
    try:
        print(f"\n=== æ·±åº¦æœç´¢åˆ†æä»£ç†å¯åŠ¨ ===")
        print(f"ä»»åŠ¡: {task_description}")
        print(f"å†…å®¹åˆ†æ: {'å¼€å¯' if analyze_content else 'å…³é—­'}")
        print(f"åˆ†ææ•°é‡: {limit}")
        
        # ç¬¬ä¸€æ­¥ï¼šæ‰§è¡Œæ™ºèƒ½æœç´¢
        search_results = await _intelligent_search_agent(task_description, limit * 2)
        
        if "âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç¬”è®°" in search_results:
            return search_results
        
        # ä»æœç´¢ç»“æœä¸­æå–URL
        urls = await _extract_urls_from_search_results(search_results)
        selected_urls = urls[:limit]
        
        print(f"\n=== å¼€å§‹æ·±åº¦å†…å®¹åˆ†æ ===")
        print(f"å°†åˆ†æ {len(selected_urls)} ä¸ªç¬”è®°")
        
        # ç¬¬äºŒæ­¥ï¼šå†…å®¹åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
        analyzed_notes = []
        if analyze_content and selected_urls:
            for i, url in enumerate(selected_urls, 1):
                print(f"\n--- åˆ†æç¬¬{i}ä¸ªç¬”è®° ---")
                print(f"URL: {url}")
                
                try:
                    note_analysis = await analyze_note(url)
                    if "error" not in note_analysis:
                        analyzed_notes.append(note_analysis)
                        print(f"âœ… åˆ†æå®Œæˆ: {note_analysis.get('æ ‡é¢˜', 'æœªçŸ¥æ ‡é¢˜')}")
                    else:
                        print(f"âŒ åˆ†æå¤±è´¥: {note_analysis.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
                    # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                    await asyncio.sleep(3)
                    
                except Exception as e:
                    print(f"âŒ åˆ†æç¬”è®°æ—¶å‡ºé”™: {str(e)}")
                    continue
        
        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š
        deep_report = await _generate_deep_analysis_report(
            task_description, search_results, analyzed_notes
        )
        
        return deep_report
        
    except Exception as e:
        return f"æ·±åº¦æœç´¢åˆ†ææ—¶å‡ºé”™: {str(e)}"

async def _extract_urls_from_search_results(search_results: str) -> list:
    """ä»æœç´¢ç»“æœä¸­æå–URL"""
    urls = []
    lines = search_results.split('\n')
    
    for line in lines:
        if 'ğŸ”— ' in line:
            url = line.split('ğŸ”— ', 1)[1].strip()
            if url.startswith('http'):
                urls.append(url)
    
    return urls

async def _generate_deep_analysis_report(task_description: str, search_results: str, analyzed_notes: list) -> str:
    """ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š"""
    report = f"""ğŸ§  æ·±åº¦æœç´¢åˆ†ææŠ¥å‘Š

ğŸ“‹ åˆ†æä»»åŠ¡: {task_description}

{search_results}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š å†…å®¹æ·±åº¦åˆ†æ:"""
    
    if not analyzed_notes:
        report += "\n\nâš ï¸ æœªèƒ½è·å–åˆ°ç¬”è®°å†…å®¹è¿›è¡Œæ·±åº¦åˆ†æ"
        return report
    
    # ç»Ÿè®¡åˆ†æ
    total_notes = len(analyzed_notes)
    domains = []
    all_keywords = []
    authors = []
    
    for note in analyzed_notes:
        if note.get('é¢†åŸŸ'):
            domains.extend(note['é¢†åŸŸ'])
        if note.get('å…³é”®è¯'):
            all_keywords.extend(note['å…³é”®è¯'])
        if note.get('ä½œè€…'):
            authors.append(note['ä½œè€…'])
    
    # é¢†åŸŸåˆ†å¸ƒç»Ÿè®¡
    from collections import Counter
    domain_count = Counter(domains)
    keyword_count = Counter(all_keywords)
    
    report += f"\n\nğŸ“ˆ ç»Ÿè®¡æ¦‚è§ˆ:\nâ€¢ åˆ†æç¬”è®°æ•°é‡: {total_notes}ä¸ª\nâ€¢ æ¶‰åŠé¢†åŸŸ: {len(domain_count)}ä¸ª\nâ€¢ æå–å…³é”®è¯: {len(keyword_count)}ä¸ª\nâ€¢ æ¶‰åŠä½œè€…: {len(set(authors))}ä½"
    
    # çƒ­é—¨é¢†åŸŸ
    if domain_count:
        report += "\n\nğŸ·ï¸ çƒ­é—¨é¢†åŸŸåˆ†å¸ƒ:"
        for domain, count in domain_count.most_common(5):
            percentage = (count / len(domains)) * 100
            report += f"\nâ€¢ {domain}: {count}æ¬¡ ({percentage:.1f}%)"
    
    # çƒ­é—¨å…³é”®è¯
    if keyword_count:
        report += "\n\nğŸ”¥ çƒ­é—¨å…³é”®è¯:"
        for keyword, count in keyword_count.most_common(10):
            report += f"\nâ€¢ {keyword} ({count}æ¬¡)"
    
    # è¯¦ç»†ç¬”è®°åˆ†æ
    report += "\n\nğŸ“ è¯¦ç»†ç¬”è®°åˆ†æ:\n"
    
    for i, note in enumerate(analyzed_notes, 1):
        report += f"\n{i}. ğŸ“„ {note.get('æ ‡é¢˜', 'æœªçŸ¥æ ‡é¢˜')}\n"
        report += f"   ğŸ‘¤ ä½œè€…: {note.get('ä½œè€…', 'æœªçŸ¥')}\n"
        report += f"   ğŸ·ï¸ é¢†åŸŸ: {', '.join(note.get('é¢†åŸŸ', []))}\n"
        
        content = note.get('å†…å®¹', '')
        if content and content != 'æœªèƒ½è·å–å†…å®¹':
            # æ˜¾ç¤ºå†…å®¹æ‘˜è¦
            content_preview = content[:100] + '...' if len(content) > 100 else content
            report += f"   ğŸ“– å†…å®¹æ‘˜è¦: {content_preview}\n"
        
        report += f"   ğŸ”— é“¾æ¥: {note.get('url', '')}\n"
    
    # è¶‹åŠ¿åˆ†æå’Œå»ºè®®
    report += "\n\nğŸ¯ è¶‹åŠ¿åˆ†æä¸å»ºè®®:\n"
    
    if domain_count:
        top_domain = domain_count.most_common(1)[0][0]
        report += f"â€¢ ä¸»è¦å…³æ³¨é¢†åŸŸæ˜¯ '{top_domain}'ï¼Œå»ºè®®æ·±å…¥ç ”ç©¶è¯¥é¢†åŸŸçš„æœ€æ–°è¶‹åŠ¿\n"
    
    if keyword_count:
        top_keywords = [kw for kw, _ in keyword_count.most_common(3)]
        report += f"â€¢ æ ¸å¿ƒå…³é”®è¯åŒ…æ‹¬: {', '.join(top_keywords)}ï¼Œå¯ä½œä¸ºå†…å®¹åˆ›ä½œçš„é‡ç‚¹æ–¹å‘\n"
    
    if len(set(authors)) > 1:
        report += f"â€¢ å‘ç° {len(set(authors))} ä½ä¸åŒä½œè€…ï¼Œå»ºè®®å…³æ³¨ä»–ä»¬çš„å…¶ä»–ä½œå“\n"
    
    # å†…å®¹è´¨é‡è¯„ä¼°
    quality_notes = [note for note in analyzed_notes if note.get('å†…å®¹') and len(note.get('å†…å®¹', '')) > 50]
    if quality_notes:
        quality_ratio = len(quality_notes) / total_notes * 100
        report += f"â€¢ å†…å®¹è´¨é‡è¯„ä¼°: {len(quality_notes)}/{total_notes} ä¸ªç¬”è®°æœ‰è¯¦ç»†å†…å®¹ ({quality_ratio:.1f}%)\n"
    
    report += "\nğŸ’¡ è¡ŒåŠ¨å»ºè®®:\n"
    report += "â€¢ å¯ä»¥åŸºäºçƒ­é—¨å…³é”®è¯åˆ›ä½œç›¸å…³å†…å®¹\n"
    report += "â€¢ å…³æ³¨é«˜è´¨é‡ä½œè€…çš„æ›´æ–°åŠ¨æ€\n"
    report += "â€¢ ç»“åˆè¶‹åŠ¿åˆ†æåˆ¶å®šå†…å®¹ç­–ç•¥\n"
    report += "â€¢ è€ƒè™‘åœ¨çƒ­é—¨é¢†åŸŸè¿›è¡Œæ·±åº¦å¸ƒå±€\n"
    
    return report

@mcp.tool()
async def get_note_content(url: str) -> str:
    """è·å–ç¬”è®°å†…å®¹
    
    Args:
        url: ç¬”è®° URL
    """
    login_status = await ensure_browser()
    if not login_status:
        return "è¯·å…ˆç™»å½•å°çº¢ä¹¦è´¦å·"
    
    if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
        return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
        
    try:
        # ä½¿ç”¨é€šç”¨URLå¤„ç†å‡½æ•°
        processed_url = process_url(url)
        print(f"å¤„ç†åçš„URL: {processed_url}")
        
        # è®¿é—®å¸–å­é“¾æ¥ï¼Œä¿ç•™å®Œæ•´å‚æ•°
        await main_page.goto(processed_url, timeout=60000)
        await asyncio.sleep(10)  # å¢åŠ ç­‰å¾…æ—¶é—´åˆ°10ç§’
        
        # æ£€æŸ¥æ˜¯å¦åŠ è½½äº†é”™è¯¯é¡µé¢
        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
            return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
            
        error_page = await main_page.evaluate('''
            () => {
                // æ£€æŸ¥å¸¸è§çš„é”™è¯¯ä¿¡æ¯
                const errorTexts = [
                    "å½“å‰ç¬”è®°æš‚æ—¶æ— æ³•æµè§ˆ",
                    "å†…å®¹ä¸å­˜åœ¨",
                    "é¡µé¢ä¸å­˜åœ¨",
                    "å†…å®¹å·²è¢«åˆ é™¤"
                ];
                
                for (const text of errorTexts) {
                    if (document.body.innerText.includes(text)) {
                        return {
                            isError: true,
                            errorText: text
                        };
                    }
                }
                
                return { isError: false };
            }
        ''')
        
        if error_page.get("isError", False):
            return f"æ— æ³•è·å–ç¬”è®°å†…å®¹: {error_page.get('errorText', 'æœªçŸ¥é”™è¯¯')}\nè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆæˆ–å°è¯•ä½¿ç”¨å¸¦æœ‰æœ‰æ•ˆtokençš„å®Œæ•´URLã€‚"
        
        # å¢å¼ºæ»šåŠ¨æ“ä½œä»¥ç¡®ä¿æ‰€æœ‰å†…å®¹åŠ è½½
        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
            return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
            
        await main_page.evaluate('''
            () => {
                // å…ˆæ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
                window.scrollTo(0, document.body.scrollHeight);
                setTimeout(() => { 
                    // ç„¶åæ»šåŠ¨åˆ°ä¸­é—´
                    window.scrollTo(0, document.body.scrollHeight / 2); 
                }, 1000);
                setTimeout(() => { 
                    // æœ€åå›åˆ°é¡¶éƒ¨
                    window.scrollTo(0, 0); 
                }, 2000);
            }
        ''')
        await asyncio.sleep(3)  # ç­‰å¾…æ»šåŠ¨å®Œæˆå’Œå†…å®¹åŠ è½½
        
        # æ‰“å°é¡µé¢ç»“æ„ç‰‡æ®µç”¨äºåˆ†æ
        try:
            print("æ‰“å°é¡µé¢ç»“æ„ç‰‡æ®µç”¨äºåˆ†æ")
            if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                
            page_structure = await main_page.evaluate('''
                () => {
                    // è·å–ç¬”è®°å†…å®¹åŒºåŸŸ
                    const noteContent = document.querySelector('.note-content');
                    const detailDesc = document.querySelector('#detail-desc');
                    const commentArea = document.querySelector('.comments-container, .comment-list');
                    
                    return {
                        hasNoteContent: !!noteContent,
                        hasDetailDesc: !!detailDesc,
                        hasCommentArea: !!commentArea,
                        noteContentHtml: noteContent ? noteContent.outerHTML.slice(0, 500) : null,
                        detailDescHtml: detailDesc ? detailDesc.outerHTML.slice(0, 500) : null,
                        commentAreaFirstChild: commentArea ? 
                            (commentArea.firstElementChild ? commentArea.firstElementChild.outerHTML.slice(0, 500) : null) : null,
                        pageTitle: document.title,
                        bodyText: document.body.innerText.slice(0, 500)
                    };
                }
            ''')
            print(f"é¡µé¢ç»“æ„åˆ†æ: {json.dumps(page_structure, ensure_ascii=False, indent=2)}")
            
            # å†æ¬¡æ£€æŸ¥å†…å®¹æ˜¯å¦å¯è§
            if "å½“å‰ç¬”è®°æš‚æ—¶æ— æ³•æµè§ˆ" in page_structure.get("bodyText", ""):
                return "æ— æ³•è·å–ç¬”è®°å†…å®¹: å½“å‰ç¬”è®°æš‚æ—¶æ— æ³•æµè§ˆ\nè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆæˆ–å°è¯•ä½¿ç”¨å¸¦æœ‰æœ‰æ•ˆtokençš„å®Œæ•´URLã€‚"
        except Exception as e:
            print(f"æ‰“å°é¡µé¢ç»“æ„æ—¶å‡ºé”™: {str(e)}")
        
        # è·å–å¸–å­å†…å®¹
        post_content = {}
        
        # è·å–å¸–å­æ ‡é¢˜ - æ–¹æ³•1ï¼šä½¿ç”¨idé€‰æ‹©å™¨
        try:
            print("å°è¯•è·å–æ ‡é¢˜ - æ–¹æ³•1ï¼šä½¿ç”¨idé€‰æ‹©å™¨")
            if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                
            title_element = await main_page.query_selector('#detail-title')
            if title_element:
                title = await title_element.text_content()
                post_content["æ ‡é¢˜"] = title.strip() if title else "æœªçŸ¥æ ‡é¢˜"
                print(f"æ–¹æ³•1è·å–åˆ°æ ‡é¢˜: {post_content['æ ‡é¢˜']}")
            else:
                print("æ–¹æ³•1æœªæ‰¾åˆ°æ ‡é¢˜å…ƒç´ ")
                post_content["æ ‡é¢˜"] = "æœªçŸ¥æ ‡é¢˜"
        except Exception as e:
            print(f"æ–¹æ³•1è·å–æ ‡é¢˜å‡ºé”™: {str(e)}")
            post_content["æ ‡é¢˜"] = "æœªçŸ¥æ ‡é¢˜"
        
        # è·å–å¸–å­æ ‡é¢˜ - æ–¹æ³•2ï¼šä½¿ç”¨classé€‰æ‹©å™¨
        if post_content["æ ‡é¢˜"] == "æœªçŸ¥æ ‡é¢˜":
            try:
                print("å°è¯•è·å–æ ‡é¢˜ - æ–¹æ³•2ï¼šä½¿ç”¨classé€‰æ‹©å™¨")
                if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                    return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                    
                title_element = await main_page.query_selector('div.title')
                if title_element:
                    title = await title_element.text_content()
                    post_content["æ ‡é¢˜"] = title.strip() if title else "æœªçŸ¥æ ‡é¢˜"
                    print(f"æ–¹æ³•2è·å–åˆ°æ ‡é¢˜: {post_content['æ ‡é¢˜']}")
                else:
                    print("æ–¹æ³•2æœªæ‰¾åˆ°æ ‡é¢˜å…ƒç´ ")
            except Exception as e:
                print(f"æ–¹æ³•2è·å–æ ‡é¢˜å‡ºé”™: {str(e)}")
        
        # è·å–å¸–å­æ ‡é¢˜ - æ–¹æ³•3ï¼šä½¿ç”¨JavaScript
        if post_content["æ ‡é¢˜"] == "æœªçŸ¥æ ‡é¢˜":
            try:
                print("å°è¯•è·å–æ ‡é¢˜ - æ–¹æ³•3ï¼šä½¿ç”¨JavaScript")
                if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                    return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                    
                title = await main_page.evaluate('''
                    () => {
                        // å°è¯•å¤šç§å¯èƒ½çš„æ ‡é¢˜é€‰æ‹©å™¨
                        const selectors = [
                            '#detail-title',
                            'div.title',
                            'h1',
                            'div.note-content div.title'
                        ];
                        
                        for (const selector of selectors) {
                            const el = document.querySelector(selector);
                            if (el && el.textContent.trim()) {
                                return el.textContent.trim();
                            }
                        }
                        return null;
                    }
                ''')
                if title:
                    post_content["æ ‡é¢˜"] = title
                    print(f"æ–¹æ³•3è·å–åˆ°æ ‡é¢˜: {post_content['æ ‡é¢˜']}")
                else:
                    print("æ–¹æ³•3æœªæ‰¾åˆ°æ ‡é¢˜å…ƒç´ ")
            except Exception as e:
                print(f"æ–¹æ³•3è·å–æ ‡é¢˜å‡ºé”™: {str(e)}")
        
        # è·å–ä½œè€… - æ–¹æ³•1ï¼šä½¿ç”¨usernameç±»é€‰æ‹©å™¨
        try:
            print("å°è¯•è·å–ä½œè€… - æ–¹æ³•1ï¼šä½¿ç”¨usernameç±»é€‰æ‹©å™¨")
            author_element = await main_page.query_selector('span.username')
            if author_element:
                author = await author_element.text_content()
                post_content["ä½œè€…"] = author.strip() if author else "æœªçŸ¥ä½œè€…"
                print(f"æ–¹æ³•1è·å–åˆ°ä½œè€…: {post_content['ä½œè€…']}")
            else:
                print("æ–¹æ³•1æœªæ‰¾åˆ°ä½œè€…å…ƒç´ ")
                post_content["ä½œè€…"] = "æœªçŸ¥ä½œè€…"
        except Exception as e:
            print(f"æ–¹æ³•1è·å–ä½œè€…å‡ºé”™: {str(e)}")
            post_content["ä½œè€…"] = "æœªçŸ¥ä½œè€…"
        
        # è·å–ä½œè€… - æ–¹æ³•2ï¼šä½¿ç”¨é“¾æ¥é€‰æ‹©å™¨
        if post_content["ä½œè€…"] == "æœªçŸ¥ä½œè€…":
            try:
                print("å°è¯•è·å–ä½œè€… - æ–¹æ³•2ï¼šä½¿ç”¨é“¾æ¥é€‰æ‹©å™¨")
                author_element = await main_page.query_selector('a.name')
                if author_element:
                    author = await author_element.text_content()
                    post_content["ä½œè€…"] = author.strip() if author else "æœªçŸ¥ä½œè€…"
                    print(f"æ–¹æ³•2è·å–åˆ°ä½œè€…: {post_content['ä½œè€…']}")
                else:
                    print("æ–¹æ³•2æœªæ‰¾åˆ°ä½œè€…å…ƒç´ ")
            except Exception as e:
                print(f"æ–¹æ³•2è·å–ä½œè€…å‡ºé”™: {str(e)}")
        
        # è·å–ä½œè€… - æ–¹æ³•3ï¼šä½¿ç”¨JavaScript
        if post_content["ä½œè€…"] == "æœªçŸ¥ä½œè€…":
            try:
                print("å°è¯•è·å–ä½œè€… - æ–¹æ³•3ï¼šä½¿ç”¨JavaScript")
                author = await main_page.evaluate('''
                    () => {
                        // å°è¯•å¤šç§å¯èƒ½çš„ä½œè€…é€‰æ‹©å™¨
                        const selectors = [
                            'span.username',
                            'a.name',
                            '.author-wrapper .username',
                            '.info .name'
                        ];
                        
                        for (const selector of selectors) {
                            const el = document.querySelector(selector);
                            if (el && el.textContent.trim()) {
                                return el.textContent.trim();
                            }
                        }
                        return null;
                    }
                ''')
                if author:
                    post_content["ä½œè€…"] = author
                    print(f"æ–¹æ³•3è·å–åˆ°ä½œè€…: {post_content['ä½œè€…']}")
                else:
                    print("æ–¹æ³•3æœªæ‰¾åˆ°ä½œè€…å…ƒç´ ")
            except Exception as e:
                print(f"æ–¹æ³•3è·å–ä½œè€…å‡ºé”™: {str(e)}")
        
        # è·å–å‘å¸ƒæ—¶é—´ - æ–¹æ³•1ï¼šä½¿ç”¨dateç±»é€‰æ‹©å™¨
        try:
            print("å°è¯•è·å–å‘å¸ƒæ—¶é—´ - æ–¹æ³•1ï¼šä½¿ç”¨dateç±»é€‰æ‹©å™¨")
            time_element = await main_page.query_selector('span.date')
            if time_element:
                time_text = await time_element.text_content()
                post_content["å‘å¸ƒæ—¶é—´"] = time_text.strip() if time_text else "æœªçŸ¥"
                print(f"æ–¹æ³•1è·å–åˆ°å‘å¸ƒæ—¶é—´: {post_content['å‘å¸ƒæ—¶é—´']}")
            else:
                print("æ–¹æ³•1æœªæ‰¾åˆ°å‘å¸ƒæ—¶é—´å…ƒç´ ")
                post_content["å‘å¸ƒæ—¶é—´"] = "æœªçŸ¥"
        except Exception as e:
            print(f"æ–¹æ³•1è·å–å‘å¸ƒæ—¶é—´å‡ºé”™: {str(e)}")
            post_content["å‘å¸ƒæ—¶é—´"] = "æœªçŸ¥"
        
        # è·å–å‘å¸ƒæ—¶é—´ - æ–¹æ³•2ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
        if post_content["å‘å¸ƒæ—¶é—´"] == "æœªçŸ¥":
            try:
                print("å°è¯•è·å–å‘å¸ƒæ—¶é—´ - æ–¹æ³•2ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…")
                time_selectors = [
                    'text=/ç¼–è¾‘äº/',
                    r'text=/\d{2}-\d{2}/',
                    r'text=/\d{4}-\d{2}-\d{2}/',
                    r'text=/\d+æœˆ\d+æ—¥/',
                    r'text=/\d+å¤©å‰/',
                    r'text=/\d+å°æ—¶å‰/',
                    'text=/ä»Šå¤©/',
                    'text=/æ˜¨å¤©/'
                ]
                
                for selector in time_selectors:
                    time_element = await main_page.query_selector(selector)
                    if time_element:
                        time_text = await time_element.text_content()
                        post_content["å‘å¸ƒæ—¶é—´"] = time_text.strip() if time_text else "æœªçŸ¥"
                        print(f"æ–¹æ³•2è·å–åˆ°å‘å¸ƒæ—¶é—´: {post_content['å‘å¸ƒæ—¶é—´']}")
                        break
                    else:
                        print(f"æ–¹æ³•2æœªæ‰¾åˆ°å‘å¸ƒæ—¶é—´å…ƒç´ : {selector}")
            except Exception as e:
                print(f"æ–¹æ³•2è·å–å‘å¸ƒæ—¶é—´å‡ºé”™: {str(e)}")
        
        # è·å–å‘å¸ƒæ—¶é—´ - æ–¹æ³•3ï¼šä½¿ç”¨JavaScript
        if post_content["å‘å¸ƒæ—¶é—´"] == "æœªçŸ¥":
            try:
                print("å°è¯•è·å–å‘å¸ƒæ—¶é—´ - æ–¹æ³•3ï¼šä½¿ç”¨JavaScript")
                time_text = await main_page.evaluate('''
                    () => {
                        // å°è¯•å¤šç§å¯èƒ½çš„æ—¶é—´é€‰æ‹©å™¨
                        const selectors = [
                            'span.date',
                            '.bottom-container .date',
                            '.date'
                        ];
                        
                        for (const selector of selectors) {
                            const el = document.querySelector(selector);
                            if (el && el.textContent.trim()) {
                                return el.textContent.trim();
                            }
                        }
                        
                        // å°è¯•æŸ¥æ‰¾åŒ…å«æ—¥æœŸæ ¼å¼çš„æ–‡æœ¬
                        const dateRegexes = [
                            /ç¼–è¾‘äº\\s*([\\d-]+)/,
                            /(\\d{2}-\\d{2})/,
                            /(\\d{4}-\\d{2}-\\d{2})/,
                            /(\\d+æœˆ\\d+æ—¥)/,
                            /(\\d+å¤©å‰)/,
                            /(\\d+å°æ—¶å‰)/,
                            /(ä»Šå¤©)/,
                            /(æ˜¨å¤©)/
                        ];
                        
                        const allText = document.body.textContent;
                        for (const regex of dateRegexes) {
                            const match = allText.match(regex);
                            if (match) {
                                return match[0];
                            }
                        }
                        
                        return null;
                    }
                ''')
                if time_text:
                    post_content["å‘å¸ƒæ—¶é—´"] = time_text
                    print(f"æ–¹æ³•3è·å–åˆ°å‘å¸ƒæ—¶é—´: {post_content['å‘å¸ƒæ—¶é—´']}")
                else:
                    print("æ–¹æ³•3æœªæ‰¾åˆ°å‘å¸ƒæ—¶é—´å…ƒç´ ")
            except Exception as e:
                print(f"æ–¹æ³•3è·å–å‘å¸ƒæ—¶é—´å‡ºé”™: {str(e)}")
        
        # è·å–å¸–å­æ­£æ–‡å†…å®¹ - æ–¹æ³•1ï¼šä½¿ç”¨ç²¾ç¡®çš„IDå’Œclassé€‰æ‹©å™¨
        try:
            print("å°è¯•è·å–æ­£æ–‡å†…å®¹ - æ–¹æ³•1ï¼šä½¿ç”¨ç²¾ç¡®çš„IDå’Œclassé€‰æ‹©å™¨")
            
            # å…ˆæ˜ç¡®æ ‡è®°è¯„è®ºåŒºåŸŸ
            await main_page.evaluate('''
                () => {
                    const commentSelectors = [
                        '.comments-container', 
                        '.comment-list',
                        '.feed-comment',
                        'div[data-v-aed4aacc]',  // æ ¹æ®æ‚¨æä¾›çš„è¯„è®ºHTMLç»“æ„
                        '.content span.note-text'  // è¯„è®ºä¸­çš„note-textç»“æ„
                    ];
                    
                    for (const selector of commentSelectors) {
                        const elements = document.querySelectorAll(selector);
                        elements.forEach(el => {
                            if (el) {
                                el.setAttribute('data-is-comment', 'true');
                                console.log('æ ‡è®°è¯„è®ºåŒºåŸŸ:', el.tagName, el.className);
                            }
                        });
                    }
                }
            ''')
            
            # å…ˆå°è¯•è·å–detail-descå’Œnote-textç»„åˆ
            content_element = await main_page.query_selector('#detail-desc .note-text')
            if content_element:
                # æ£€æŸ¥æ˜¯å¦åœ¨è¯„è®ºåŒºåŸŸå†…
                is_in_comment = await content_element.evaluate('(el) => !!el.closest("[data-is-comment=\'true\']") || false')
                if not is_in_comment:
                    content_text = await content_element.text_content()
                    if content_text and len(content_text.strip()) > 50:  # å¢åŠ é•¿åº¦é˜ˆå€¼
                        post_content["å†…å®¹"] = content_text.strip()
                        print(f"æ–¹æ³•1è·å–åˆ°æ­£æ–‡å†…å®¹ï¼Œé•¿åº¦: {len(post_content['å†…å®¹'])}")
                    else:
                        print(f"æ–¹æ³•1è·å–åˆ°çš„å†…å®¹å¤ªçŸ­: {len(content_text.strip()) if content_text else 0}")
                        post_content["å†…å®¹"] = "æœªèƒ½è·å–å†…å®¹"
                else:
                    print("æ–¹æ³•1æ‰¾åˆ°çš„å…ƒç´ åœ¨è¯„è®ºåŒºåŸŸå†…ï¼Œè·³è¿‡")
                    post_content["å†…å®¹"] = "æœªèƒ½è·å–å†…å®¹"
            else:
                print("æ–¹æ³•1æœªæ‰¾åˆ°æ­£æ–‡å†…å®¹å…ƒç´ ")
                post_content["å†…å®¹"] = "æœªèƒ½è·å–å†…å®¹"
        except Exception as e:
            print(f"æ–¹æ³•1è·å–æ­£æ–‡å†…å®¹å‡ºé”™: {str(e)}")
            post_content["å†…å®¹"] = "æœªèƒ½è·å–å†…å®¹"
        
        # è·å–å¸–å­æ­£æ–‡å†…å®¹ - æ–¹æ³•2ï¼šä½¿ç”¨XPathé€‰æ‹©å™¨
        if post_content["å†…å®¹"] == "æœªèƒ½è·å–å†…å®¹":
            try:
                print("å°è¯•è·å–æ­£æ–‡å†…å®¹ - æ–¹æ³•2ï¼šä½¿ç”¨XPathé€‰æ‹©å™¨")
                # ä½¿ç”¨XPathè·å–ç¬”è®°å†…å®¹åŒºåŸŸ
                content_text = await main_page.evaluate('''
                    () => {
                        const xpath = '//div[@id="detail-desc"]/span[@class="note-text"]';
                        const result = document.evaluate(xpath, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null);
                        const element = result.singleNodeValue;
                        return element ? element.textContent.trim() : null;
                    }
                ''')
                
                if content_text and len(content_text) > 20:
                    post_content["å†…å®¹"] = content_text
                    print(f"æ–¹æ³•2è·å–åˆ°æ­£æ–‡å†…å®¹ï¼Œé•¿åº¦: {len(post_content['å†…å®¹'])}")
                else:
                    print(f"æ–¹æ³•2è·å–åˆ°çš„å†…å®¹å¤ªçŸ­æˆ–ä¸ºç©º: {len(content_text) if content_text else 0}")
            except Exception as e:
                print(f"æ–¹æ³•2è·å–æ­£æ–‡å†…å®¹å‡ºé”™: {str(e)}")
        
        # è·å–å¸–å­æ­£æ–‡å†…å®¹ - æ–¹æ³•3ï¼šä½¿ç”¨JavaScriptè·å–æœ€é•¿æ–‡æœ¬
        if post_content["å†…å®¹"] == "æœªèƒ½è·å–å†…å®¹":
            try:
                print("å°è¯•è·å–æ­£æ–‡å†…å®¹ - æ–¹æ³•3ï¼šä½¿ç”¨JavaScriptè·å–æœ€é•¿æ–‡æœ¬")
                content_text = await main_page.evaluate('''
                    () => {
                        // å®šä¹‰è¯„è®ºåŒºåŸŸé€‰æ‹©å™¨
                        const commentSelectors = [
                            '.comments-container', 
                            '.comment-list',
                            '.feed-comment',
                            'div[data-v-aed4aacc]',
                            '.comment-item',
                            '[data-is-comment="true"]'
                        ];
                        
                        // æ‰¾åˆ°æ‰€æœ‰è¯„è®ºåŒºåŸŸ
                        let commentAreas = [];
                        for (const selector of commentSelectors) {
                            const elements = document.querySelectorAll(selector);
                            elements.forEach(el => commentAreas.push(el));
                        }
                        
                        // æŸ¥æ‰¾å¯èƒ½çš„å†…å®¹å…ƒç´ ï¼Œæ’é™¤è¯„è®ºåŒº
                        const contentElements = Array.from(document.querySelectorAll('div#detail-desc, div.note-content, div.desc, span.note-text'))
                            .filter(el => {
                                // æ£€æŸ¥æ˜¯å¦åœ¨è¯„è®ºåŒºåŸŸå†…
                                const isInComment = commentAreas.some(commentArea => 
                                    commentArea && commentArea.contains(el));
                                
                                if (isInComment) {
                                    console.log('æ’é™¤è¯„è®ºåŒºåŸŸå†…å®¹:', el.tagName, el.className);
                                    return false;
                                }
                                
                                const text = el.textContent.trim();
                                return text.length > 100 && text.length < 10000;
                            })
                            .sort((a, b) => b.textContent.length - a.textContent.length);
                        
                        if (contentElements.length > 0) {
                            console.log('æ‰¾åˆ°å†…å®¹å…ƒç´ :', contentElements[0].tagName, contentElements[0].className);
                            return contentElements[0].textContent.trim();
                        }
                        
                        return null;
                    }
                ''')
                
                if content_text and len(content_text) > 100:  # å¢åŠ é•¿åº¦é˜ˆå€¼
                    post_content["å†…å®¹"] = content_text
                    print(f"æ–¹æ³•3è·å–åˆ°æ­£æ–‡å†…å®¹ï¼Œé•¿åº¦: {len(post_content['å†…å®¹'])}")
                else:
                    print(f"æ–¹æ³•3è·å–åˆ°çš„å†…å®¹å¤ªçŸ­æˆ–ä¸ºç©º: {len(content_text) if content_text else 0}")
            except Exception as e:
                print(f"æ–¹æ³•3è·å–æ­£æ–‡å†…å®¹å‡ºé”™: {str(e)}")
        
        # è·å–å¸–å­æ­£æ–‡å†…å®¹ - æ–¹æ³•4ï¼šåŒºåˆ†æ­£æ–‡å’Œè¯„è®ºå†…å®¹
        if post_content["å†…å®¹"] == "æœªèƒ½è·å–å†…å®¹":
            try:
                print("å°è¯•è·å–æ­£æ–‡å†…å®¹ - æ–¹æ³•4ï¼šåŒºåˆ†æ­£æ–‡å’Œè¯„è®ºå†…å®¹")
                content_text = await main_page.evaluate('''
                    () => {
                        // é¦–å…ˆå°è¯•è·å–note-contentåŒºåŸŸ
                        const noteContent = document.querySelector('.note-content');
                        if (noteContent) {
                            // æŸ¥æ‰¾note-textï¼Œè¿™é€šå¸¸åŒ…å«ä¸»è¦å†…å®¹
                            const noteText = noteContent.querySelector('.note-text');
                            if (noteText && noteText.textContent.trim().length > 50) {
                                return noteText.textContent.trim();
                            }
                            
                            // å¦‚æœæ²¡æœ‰æ‰¾åˆ°note-textæˆ–å†…å®¹å¤ªçŸ­ï¼Œè¿”å›æ•´ä¸ªnote-content
                            if (noteContent.textContent.trim().length > 50) {
                                return noteContent.textContent.trim();
                            }
                        }
                        
                        // å¦‚æœä¸Šé¢çš„æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œå°è¯•è·å–æ‰€æœ‰æ®µè½å¹¶æ‹¼æ¥
                        const paragraphs = Array.from(document.querySelectorAll('p'))
                            .filter(p => {
                                // æ’é™¤è¯„è®ºåŒºæ®µè½
                                const isInComments = p.closest('.comments-container, .comment-list');
                                return !isInComments && p.textContent.trim().length > 10;
                            });
                            
                        if (paragraphs.length > 0) {
                            return paragraphs.map(p => p.textContent.trim()).join('\n\n');
                        }
                        
                        return null;
                    }
                ''')
                
                if content_text and len(content_text) > 50:
                    post_content["å†…å®¹"] = content_text
                    print(f"æ–¹æ³•4è·å–åˆ°æ­£æ–‡å†…å®¹ï¼Œé•¿åº¦: {len(post_content['å†…å®¹'])}")
                else:
                    print(f"æ–¹æ³•4è·å–åˆ°çš„å†…å®¹å¤ªçŸ­æˆ–ä¸ºç©º: {len(content_text) if content_text else 0}")
            except Exception as e:
                print(f"æ–¹æ³•4è·å–æ­£æ–‡å†…å®¹å‡ºé”™: {str(e)}")
        
        # è·å–å¸–å­æ­£æ–‡å†…å®¹ - æ–¹æ³•5ï¼šç›´æ¥é€šè¿‡DOMç»“æ„å®šä½
        if post_content["å†…å®¹"] == "æœªèƒ½è·å–å†…å®¹":
            try:
                print("å°è¯•è·å–æ­£æ–‡å†…å®¹ - æ–¹æ³•5ï¼šç›´æ¥é€šè¿‡DOMç»“æ„å®šä½")
                content_text = await main_page.evaluate('''
                    () => {
                        // æ ¹æ®æ‚¨æä¾›çš„HTMLç»“æ„ç›´æ¥å®šä½
                        const noteContent = document.querySelector('div.note-content');
                        if (noteContent) {
                            const detailTitle = noteContent.querySelector('#detail-title');
                            const detailDesc = noteContent.querySelector('#detail-desc');
                            
                            if (detailDesc) {
                                const noteText = detailDesc.querySelector('span.note-text');
                                if (noteText) {
                                    return noteText.textContent.trim();
                                }
                                return detailDesc.textContent.trim();
                            }
                        }
                        
                        // å°è¯•å…¶ä»–å¯èƒ½çš„ç»“æ„
                        const descElements = document.querySelectorAll('div.desc');
                        for (const desc of descElements) {
                            // æ£€æŸ¥æ˜¯å¦åœ¨è¯„è®ºåŒº
                            const isInComment = desc.closest('.comments-container, .comment-list, .feed-comment');
                            if (!isInComment && desc.textContent.trim().length > 100) {
                                return desc.textContent.trim();
                            }
                        }
                        
                        return null;
                    }
                ''')
                
                if content_text and len(content_text) > 100:
                    post_content["å†…å®¹"] = content_text
                    print(f"æ–¹æ³•5è·å–åˆ°æ­£æ–‡å†…å®¹ï¼Œé•¿åº¦: {len(post_content['å†…å®¹'])}")
                else:
                    print(f"æ–¹æ³•5è·å–åˆ°çš„å†…å®¹å¤ªçŸ­æˆ–ä¸ºç©º: {len(content_text) if content_text else 0}")
            except Exception as e:
                print(f"æ–¹æ³•5è·å–æ­£æ–‡å†…å®¹å‡ºé”™: {str(e)}")
        
        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        result = f"æ ‡é¢˜: {post_content['æ ‡é¢˜']}\n"
        result += f"ä½œè€…: {post_content['ä½œè€…']}\n"
        result += f"å‘å¸ƒæ—¶é—´: {post_content['å‘å¸ƒæ—¶é—´']}\n"
        result += f"é“¾æ¥: {url}\n\n"
        result += f"å†…å®¹:\n{post_content['å†…å®¹']}"
        
        return result
    
    except Exception as e:
        return f"è·å–ç¬”è®°å†…å®¹æ—¶å‡ºé”™: {str(e)}"

@mcp.tool()
async def get_note_comments(url: str) -> str:
    """è·å–ç¬”è®°è¯„è®º
    
    Args:
        url: ç¬”è®° URL
    """
    login_status = await ensure_browser()
    if not login_status:
        return "è¯·å…ˆç™»å½•å°çº¢ä¹¦è´¦å·"
    
    if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
        return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
        
    try:
        # å¤„ç†URL
        processed_url = process_url(url)
        print(f"å¤„ç†åçš„è¯„è®ºURL: {processed_url}")
        
        # è®¿é—®å¸–å­é“¾æ¥
        await main_page.goto(processed_url, timeout=60000)
        await asyncio.sleep(5)  # ç­‰å¾…é¡µé¢åŠ è½½
        
        # æ£€æŸ¥æ˜¯å¦åŠ è½½äº†é”™è¯¯é¡µé¢
        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
            return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
            
        error_page = await main_page.evaluate('''
            () => {
                // æ£€æŸ¥å¸¸è§çš„é”™è¯¯ä¿¡æ¯
                const errorTexts = [
                    "å½“å‰ç¬”è®°æš‚æ—¶æ— æ³•æµè§ˆ",
                    "å†…å®¹ä¸å­˜åœ¨",
                    "é¡µé¢ä¸å­˜åœ¨",
                    "å†…å®¹å·²è¢«åˆ é™¤"
                ];
                
                for (const text of errorTexts) {
                    if (document.body.innerText.includes(text)) {
                        return {
                            isError: true,
                            errorText: text
                        };
                    }
                }
                
                return { isError: false };
            }
        ''')
        
        if error_page.get("isError", False):
            return f"æ— æ³•è·å–ç¬”è®°è¯„è®º: {error_page.get('errorText', 'æœªçŸ¥é”™è¯¯')}\nè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆæˆ–å°è¯•ä½¿ç”¨å¸¦æœ‰æœ‰æ•ˆtokençš„å®Œæ•´URLã€‚"
        
        # å…ˆæ»šåŠ¨åˆ°è¯„è®ºåŒº
        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
            return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
            
        comment_section_locators = []
        try:
            comment_section_locators = [
                main_page.get_by_text("æ¡è¯„è®º", exact=False),
                main_page.get_by_text("è¯„è®º", exact=False),
                main_page.locator("text=è¯„è®º").first
            ]
        except Exception as e:
            print(f"åˆ›å»ºè¯„è®ºåŒºå®šä½å™¨æ—¶å‡ºé”™: {str(e)}")
            # ç»§ç»­æ‰§è¡Œï¼Œä¸é˜»æ–­ç¨‹åº
        
        for locator in comment_section_locators:
            try:
                if locator and await locator.count() > 0:  # æ·»åŠ ç©ºæ£€æŸ¥
                    await locator.scroll_into_view_if_needed(timeout=5000)
                    await asyncio.sleep(2)
                    break
            except Exception as e:
                print(f"æ»šåŠ¨åˆ°è¯„è®ºåŒºæ—¶å‡ºé”™: {str(e)}")
                continue
        
        # æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šè¯„è®º
        for i in range(8):
            try:
                if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                    break
                    
                await main_page.evaluate("window.scrollBy(0, 500)")
                await asyncio.sleep(1)
                
                # å°è¯•ç‚¹å‡»"æŸ¥çœ‹æ›´å¤šè¯„è®º"æŒ‰é’®
                more_comment_selectors = [
                    "text=æŸ¥çœ‹æ›´å¤šè¯„è®º",
                    "text=å±•å¼€æ›´å¤šè¯„è®º",
                    "text=åŠ è½½æ›´å¤š",
                    "text=æŸ¥çœ‹å…¨éƒ¨"
                ]
                
                for selector in more_comment_selectors:
                    try:
                        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                            break
                            
                        more_btn = main_page.locator(selector).first
                        if more_btn and await more_btn.count() > 0 and await more_btn.is_visible():  # æ·»åŠ ç©ºæ£€æŸ¥
                            await more_btn.click()
                            await asyncio.sleep(2)
                    except Exception as e:
                        print(f"ç‚¹å‡»æŸ¥çœ‹æ›´å¤šæŒ‰é’®æ—¶å‡ºé”™: {str(e)}")
                        continue
            except Exception as e:
                print(f"æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šè¯„è®ºæ—¶å‡ºé”™: {str(e)}")
                pass
        
        # è·å–è¯„è®º
        comments = []
        
        # ä½¿ç”¨ç‰¹å®šè¯„è®ºé€‰æ‹©å™¨
        comment_selectors = [
            "div.comment-item", 
            "div.commentItem",
            "div.comment-content",
            "div.comment-wrapper",
            "section.comment",
            "div.feed-comment"
        ]
        
        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
            return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
            
        for selector in comment_selectors:
            try:
                comment_elements = main_page.locator(selector)
                if comment_elements:  # æ·»åŠ ç©ºæ£€æŸ¥
                    count = await comment_elements.count()
                    if count > 0:
                        for i in range(count):
                            try:
                                comment_element = comment_elements.nth(i)
                                if not comment_element:  # æ·»åŠ ç©ºæ£€æŸ¥
                                    continue
                                    
                                # æå–è¯„è®ºè€…åç§°
                                username = "æœªçŸ¥ç”¨æˆ·"
                                username_selectors = ["span.user-name", "a.name", "div.username", "span.nickname", "a.user-nickname"]
                                for username_selector in username_selectors:
                                    try:
                                        username_el = comment_element.locator(username_selector).first
                                        if username_el and await username_el.count() > 0:  # æ·»åŠ ç©ºæ£€æŸ¥
                                            username_text = await username_el.text_content()
                                            if username_text:  # æ·»åŠ ç©ºæ£€æŸ¥
                                                username = username_text.strip()
                                                break
                                    except Exception as e:
                                        print(f"è·å–ç”¨æˆ·åå‡ºé”™: {str(e)}")
                                        continue
                                
                                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•é€šè¿‡ç”¨æˆ·é“¾æ¥æŸ¥æ‰¾
                                if username == "æœªçŸ¥ç”¨æˆ·":
                                    try:
                                        user_link = comment_element.locator('a[href*="/user/profile/"]').first
                                        if user_link and await user_link.count() > 0:  # æ·»åŠ ç©ºæ£€æŸ¥
                                            username_text = await user_link.text_content()
                                            if username_text:  # æ·»åŠ ç©ºæ£€æŸ¥
                                                username = username_text.strip()
                                    except Exception as e:
                                        print(f"é€šè¿‡ç”¨æˆ·é“¾æ¥è·å–ç”¨æˆ·åå‡ºé”™: {str(e)}")
                                
                                # æå–è¯„è®ºå†…å®¹
                                content = "æœªçŸ¥å†…å®¹"
                                content_selectors = ["div.content", "p.content", "div.text", "span.content", "div.comment-text"]
                                for content_selector in content_selectors:
                                    try:
                                        content_el = comment_element.locator(content_selector).first
                                        if content_el and await content_el.count() > 0:  # æ·»åŠ ç©ºæ£€æŸ¥
                                            content_text = await content_el.text_content()
                                            if content_text:  # æ·»åŠ ç©ºæ£€æŸ¥
                                                content = content_text.strip()
                                                break
                                    except Exception as e:
                                        print(f"è·å–è¯„è®ºå†…å®¹å‡ºé”™: {str(e)}")
                                        continue
                                
                                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å†…å®¹ï¼Œå¯èƒ½å†…å®¹å°±åœ¨è¯„è®ºå…ƒç´ æœ¬èº«
                                if content == "æœªçŸ¥å†…å®¹":
                                    try:
                                        full_text = await comment_element.text_content()
                                        if full_text:  # æ·»åŠ ç©ºæ£€æŸ¥
                                            if username != "æœªçŸ¥ç”¨æˆ·" and username in full_text:
                                                content = full_text.replace(username, "").strip()
                                            else:
                                                content = full_text.strip()
                                    except Exception as e:
                                        print(f"è·å–è¯„è®ºå…¨æ–‡å‡ºé”™: {str(e)}")
                                
                                # æå–è¯„è®ºæ—¶é—´
                                time_location = "æœªçŸ¥æ—¶é—´"
                                time_selectors = ["span.time", "div.time", "span.date", "div.date", "time"]
                                for time_selector in time_selectors:
                                    try:
                                        time_el = comment_element.locator(time_selector).first
                                        if time_el and await time_el.count() > 0:  # æ·»åŠ ç©ºæ£€æŸ¥
                                            time_text = await time_el.text_content()
                                            if time_text:  # æ·»åŠ ç©ºæ£€æŸ¥
                                                time_location = time_text.strip()
                                                break
                                    except Exception as e:
                                        print(f"è·å–è¯„è®ºæ—¶é—´å‡ºé”™: {str(e)}")
                                        continue
                                
                                # å¦‚æœå†…å®¹æœ‰è¶³å¤Ÿé•¿åº¦ä¸”æ‰¾åˆ°ç”¨æˆ·åï¼Œæ·»åŠ è¯„è®º
                                if username != "æœªçŸ¥ç”¨æˆ·" and content != "æœªçŸ¥å†…å®¹" and len(content) > 2:
                                    comments.append({
                                        "ç”¨æˆ·å": username,
                                        "å†…å®¹": content,
                                        "æ—¶é—´": time_location
                                    })
                            except Exception as e:
                                print(f"å¤„ç†å•ä¸ªè¯„è®ºå‡ºé”™: {str(e)}")
                                continue
                        
                        # å¦‚æœæ‰¾åˆ°äº†è¯„è®ºï¼Œå°±ä¸ç»§ç»­å°è¯•å…¶ä»–é€‰æ‹©å™¨äº†
                        if comments:
                            break
            except Exception as e:
                print(f"å¤„ç†è¯„è®ºé€‰æ‹©å™¨å‡ºé”™: {str(e)}")
                continue
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯„è®ºï¼Œå°è¯•ä½¿ç”¨å…¶ä»–æ–¹æ³•
        if not comments:
            # è·å–æ‰€æœ‰ç”¨æˆ·åå…ƒç´ 
            username_elements = main_page.locator('a[href*="/user/profile/"]')
            username_count = await username_elements.count()
            
            if username_count > 0:
                for i in range(username_count):
                    try:
                        username_element = username_elements.nth(i)
                        username = await username_element.text_content()
                        
                        # å°è¯•è·å–è¯„è®ºå†…å®¹
                        content = await main_page.evaluate('''
                            (usernameElement) => {
                                const parent = usernameElement.parentElement;
                                if (!parent) return null;
                                
                                // å°è¯•è·å–åŒçº§çš„ä¸‹ä¸€ä¸ªå…ƒç´ 
                                let sibling = usernameElement.nextElementSibling;
                                while (sibling) {
                                    const text = sibling.textContent.trim();
                                    if (text) return text;
                                    sibling = sibling.nextElementSibling;
                                }
                                
                                // å°è¯•è·å–çˆ¶å…ƒç´ çš„æ–‡æœ¬ï¼Œå¹¶è¿‡æ»¤æ‰ç”¨æˆ·å
                                const allText = parent.textContent.trim();
                                if (allText && allText.includes(usernameElement.textContent.trim())) {
                                    return allText.replace(usernameElement.textContent.trim(), '').trim();
                                }
                                
                                return null;
                            }
                        ''', username_element)
                        
                        if username and content:
                            comments.append({
                                "ç”¨æˆ·å": username.strip(),
                                "å†…å®¹": content.strip(),
                                "æ—¶é—´": "æœªçŸ¥æ—¶é—´"
                            })
                    except Exception:
                        continue
        
        # æ ¼å¼åŒ–è¿”å›ç»“æœ
        if comments:
            result = f"å…±è·å–åˆ° {len(comments)} æ¡è¯„è®ºï¼š\n\n"
            for i, comment in enumerate(comments, 1):
                result += f"{i}. {comment['ç”¨æˆ·å']}ï¼ˆ{comment['æ—¶é—´']}ï¼‰: {comment['å†…å®¹']}\n\n"
            return result
        else:
            return "æœªæ‰¾åˆ°ä»»ä½•è¯„è®ºï¼Œå¯èƒ½æ˜¯å¸–å­æ²¡æœ‰è¯„è®ºæˆ–è¯„è®ºåŒºæ— æ³•è®¿é—®ã€‚"
    
    except Exception as e:
        return f"è·å–è¯„è®ºæ—¶å‡ºé”™: {str(e)}"

@mcp.tool()
async def analyze_note(url: str) -> dict:
    """è·å–å¹¶åˆ†æç¬”è®°å†…å®¹ï¼Œè¿”å›ç¬”è®°çš„è¯¦ç»†ä¿¡æ¯ä¾›AIç”Ÿæˆè¯„è®º
    
    Args:
        url: ç¬”è®° URL
    """
    login_status = await ensure_browser()
    if not login_status:
        return {"error": "è¯·å…ˆç™»å½•å°çº¢ä¹¦è´¦å·"}
    
    try:
        # å¤„ç†URL
        processed_url = process_url(url)
        
        # ç›´æ¥è°ƒç”¨get_note_contentè·å–ç¬”è®°å†…å®¹
        note_content_result = await get_note_content(processed_url)
        
        # æ£€æŸ¥æ˜¯å¦è·å–æˆåŠŸ
        if note_content_result.startswith("è¯·å…ˆç™»å½•") or note_content_result.startswith("æ— æ³•è·å–ç¬”è®°å†…å®¹") or note_content_result.startswith("è·å–ç¬”è®°å†…å®¹æ—¶å‡ºé”™"):
            return {"error": note_content_result}
        
        # è§£æè·å–åˆ°çš„ç¬”è®°å†…å®¹
        content_lines = note_content_result.strip().split('\n')
        post_content = {}
        
        # æå–æ ‡é¢˜ã€ä½œè€…ã€å‘å¸ƒæ—¶é—´å’Œå†…å®¹
        for i, line in enumerate(content_lines):
            if line.startswith("æ ‡é¢˜:"):
                post_content["æ ‡é¢˜"] = line.replace("æ ‡é¢˜:", "").strip()
            elif line.startswith("ä½œè€…:"):
                post_content["ä½œè€…"] = line.replace("ä½œè€…:", "").strip()
            elif line.startswith("å‘å¸ƒæ—¶é—´:"):
                post_content["å‘å¸ƒæ—¶é—´"] = line.replace("å‘å¸ƒæ—¶é—´:", "").strip()
            elif line.startswith("å†…å®¹:"):
                # å†…å®¹å¯èƒ½æœ‰å¤šè¡Œï¼Œè·å–å‰©ä½™æ‰€æœ‰è¡Œ
                content_text = "\n".join(content_lines[i+1:]).strip()
                post_content["å†…å®¹"] = content_text
                break
        
        # å¦‚æœæ²¡æœ‰æå–åˆ°æ ‡é¢˜æˆ–å†…å®¹ï¼Œè®¾ç½®é»˜è®¤å€¼
        if "æ ‡é¢˜" not in post_content or not post_content["æ ‡é¢˜"]:
            post_content["æ ‡é¢˜"] = "æœªçŸ¥æ ‡é¢˜"
        if "ä½œè€…" not in post_content or not post_content["ä½œè€…"]:
            post_content["ä½œè€…"] = "æœªçŸ¥ä½œè€…"
        if "å†…å®¹" not in post_content or not post_content["å†…å®¹"]:
            post_content["å†…å®¹"] = "æœªèƒ½è·å–å†…å®¹"
        
        # ç®€å•åˆ†è¯
        import re
        words = re.findall(r'\w+', f"{post_content.get('æ ‡é¢˜', '')} {post_content.get('å†…å®¹', '')}")
        
        # ä½¿ç”¨å¸¸è§çš„çƒ­é—¨é¢†åŸŸå…³é”®è¯
        domain_keywords = {
            "ç¾å¦†": ["å£çº¢", "ç²‰åº•", "çœ¼å½±", "æŠ¤è‚¤", "ç¾å¦†", "åŒ–å¦†", "ä¿æ¹¿", "ç²¾å", "é¢è†œ"],
            "ç©¿æ­": ["ç©¿æ­", "è¡£æœ", "æ­é…", "æ—¶å°š", "é£æ ¼", "å•å“", "è¡£æ©±", "æ½®æµ"],
            "ç¾é£Ÿ": ["ç¾é£Ÿ", "å¥½åƒ", "é£Ÿè°±", "é¤å…", "å°åƒ", "ç”œç‚¹", "çƒ˜ç„™", "èœè°±"],
            "æ—…è¡Œ": ["æ—…è¡Œ", "æ—…æ¸¸", "æ™¯ç‚¹", "å‡ºè¡Œ", "æ”»ç•¥", "æ‰“å¡", "åº¦å‡", "é…’åº—"],
            "æ¯å©´": ["å®å®", "æ¯å©´", "è‚²å„¿", "å„¿ç«¥", "å©´å„¿", "è¾…é£Ÿ", "ç©å…·"],
            "æ•°ç ": ["æ•°ç ", "æ‰‹æœº", "ç”µè„‘", "ç›¸æœº", "æ™ºèƒ½", "è®¾å¤‡", "ç§‘æŠ€"],
            "å®¶å±…": ["å®¶å±…", "è£…ä¿®", "å®¶å…·", "è®¾è®¡", "æ”¶çº³", "å¸ƒç½®", "å®¶è£…"],
            "å¥èº«": ["å¥èº«", "è¿åŠ¨", "ç˜¦èº«", "å‡è‚¥", "è®­ç»ƒ", "å¡‘å½¢", "è‚Œè‚‰"],
            "AI": ["AI", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "ç¼–ç¨‹", "å¼€å‘", "æŠ€æœ¯", "Claude", "GPT"]
        }
        
        # æ£€æµ‹å¸–å­å¯èƒ½å±äºçš„é¢†åŸŸ
        detected_domains = []
        for domain, domain_keys in domain_keywords.items():
            for key in domain_keys:
                if key.lower() in post_content.get("æ ‡é¢˜", "").lower() or key.lower() in post_content.get("å†…å®¹", "").lower():
                    detected_domains.append(domain)
                    break
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æ˜ç¡®çš„é¢†åŸŸï¼Œé»˜è®¤ä¸ºç”Ÿæ´»æ–¹å¼
        if not detected_domains:
            detected_domains = ["ç”Ÿæ´»"]
        
        # è¿”å›åˆ†æç»“æœ
        return {
            "url": url,
            "æ ‡é¢˜": post_content.get("æ ‡é¢˜", "æœªçŸ¥æ ‡é¢˜"),
            "ä½œè€…": post_content.get("ä½œè€…", "æœªçŸ¥ä½œè€…"),
            "å†…å®¹": post_content.get("å†…å®¹", "æœªèƒ½è·å–å†…å®¹"),
            "é¢†åŸŸ": detected_domains,
            "å…³é”®è¯": list(set(words))[:20]  # å–å‰20ä¸ªä¸é‡å¤çš„è¯ä½œä¸ºå…³é”®è¯
        }
    
    except Exception as e:
        return {"error": f"åˆ†æç¬”è®°å†…å®¹æ—¶å‡ºé”™: {str(e)}"}

@mcp.tool()
async def post_smart_comment(url: str, comment_type: str = "å¼•æµ") -> dict:
    """
    æ ¹æ®å¸–å­å†…å®¹å‘å¸ƒæ™ºèƒ½è¯„è®ºï¼Œå¢åŠ æ›å…‰å¹¶å¼•å¯¼ç”¨æˆ·å…³æ³¨æˆ–ç§èŠ

    Args:
        url: ç¬”è®° URL
        comment_type: è¯„è®ºç±»å‹ï¼Œå¯é€‰å€¼:
                     "å¼•æµ" - å¼•å¯¼ç”¨æˆ·å…³æ³¨æˆ–ç§èŠ
                     "ç‚¹èµ" - ç®€å•äº’åŠ¨è·å–å¥½æ„Ÿ
                     "å’¨è¯¢" - ä»¥é—®é¢˜å½¢å¼å¢åŠ äº’åŠ¨
                     "ä¸“ä¸š" - å±•ç¤ºä¸“ä¸šçŸ¥è¯†å»ºç«‹æƒå¨

    Returns:
        dict: åŒ…å«ç¬”è®°ä¿¡æ¯å’Œè¯„è®ºç±»å‹çš„å­—å…¸ï¼Œä¾›MCPå®¢æˆ·ç«¯(å¦‚Claude)ç”Ÿæˆè¯„è®º
    """
    # å¤„ç†URL
    processed_url = process_url(url)
    
    # è·å–ç¬”è®°å†…å®¹
    note_info = await analyze_note(processed_url)
    
    if "error" in note_info:
        return {"error": note_info["error"]}
    
    # è¯„è®ºç±»å‹æŒ‡å¯¼
    comment_guides = {
        "å¼•æµ": 'ç”Ÿæˆä¸€æ¡è¡¨è¾¾è®¤åŒå¹¶å¼•å¯¼äº’åŠ¨çš„è¯„è®ºã€‚å¯ä»¥æåˆ°è‡ªå·±ä¹Ÿåœ¨ç ”ç©¶ç›¸å…³å†…å®¹ï¼Œæˆ–è¡¨è¾¾å¸Œæœ›è¿›ä¸€æ­¥äº¤æµçš„æ„æ„¿ã€‚å¯ä»¥åœ¨ç»“å°¾åŠ ä¸Š"æœ‰æ›´å¤šé—®é¢˜æ¬¢è¿ç§ä¿¡æˆ‘"æˆ–"æƒ³äº†è§£æ›´å¤šå¯ä»¥æ‰¾æˆ‘èŠèŠ"ç­‰é‚€è¯·è¯­å¥ã€‚',
        "ç‚¹èµ": 'ç”Ÿæˆä¸€æ¡ç®€çŸ­çš„èµç¾è¯„è®ºï¼Œè¡¨è¾¾å¯¹å†…å®¹çš„å–œçˆ±å’Œæ”¯æŒã€‚å¯ä»¥æåˆ°ä½œè€…åå­—å’Œç¬”è®°çš„é¢†åŸŸï¼Œå¦‚"å¤ªèµäº†ï¼XXçš„åˆ†äº«æ€»æ˜¯è¿™ä¹ˆå®ç”¨"æˆ–"å–œæ¬¢è¿™ç§æ·±åº¦åˆ†äº«"ç­‰ã€‚',
        "å’¨è¯¢": 'ç”Ÿæˆä¸€æ¡æé—®å¼è¯„è®ºï¼Œé’ˆå¯¹ç¬”è®°å†…å®¹è¯¢é—®æ›´å¤šç»†èŠ‚æˆ–ç›¸å…³ä¿¡æ¯ã€‚å¯ä»¥ä½¿ç”¨"è¯·é—®åšä¸»"æˆ–"æƒ³è¯·æ•™ä¸€ä¸‹"ç­‰å¼€å¤´ï¼Œå¹¶æå‡ºä¸ç¬”è®°å†…å®¹ç›¸å…³çš„å…·ä½“é—®é¢˜ã€‚',
        "ä¸“ä¸š": 'ç”Ÿæˆä¸€æ¡å±•ç¤ºä¸“ä¸šçŸ¥è¯†çš„è¯„è®ºï¼Œé’ˆå¯¹ç¬”è®°å†…å®¹æä¾›ä¸“ä¸šè§è§£æˆ–è¡¥å……ä¿¡æ¯ã€‚å¯ä»¥ä½¿ç”¨"ä½œä¸ºè¯¥é¢†åŸŸä»ä¸šè€…"æˆ–"ä»ä¸“ä¸šè§’åº¦æ¥çœ‹"ç­‰å¼€å¤´ï¼Œå¹¶åœ¨è¯„è®ºä¸­ä½¿ç”¨ä¸ç¬”è®°é¢†åŸŸç›¸å…³çš„ä¸“ä¸šæœ¯è¯­ã€‚'
    }
    
    # è¿”å›ç¬”è®°åˆ†æç»“æœå’Œè¯„è®ºç±»å‹ï¼Œè®©MCPå®¢æˆ·ç«¯(å¦‚Claude)ç”Ÿæˆè¯„è®º
    # MCPå®¢æˆ·ç«¯ç”Ÿæˆè¯„è®ºåï¼Œåº”è°ƒç”¨post_commentå‡½æ•°å‘å¸ƒè¯„è®º
    return {
        "note_info": note_info,
        "comment_type": comment_type,
        "comment_guide": comment_guides.get(comment_type, ""),
        "url": url,  # æ·»åŠ URLä¾¿äºå®¢æˆ·ç«¯ç›´æ¥è°ƒç”¨post_comment
        "message": "è¯·æ ¹æ®ç¬”è®°å†…å®¹å’Œè¯„è®ºç±»å‹æŒ‡å—ï¼Œç›´æ¥ç”Ÿæˆä¸€æ¡è‡ªç„¶ã€ç›¸å…³çš„è¯„è®ºï¼Œå¹¶ç«‹å³å‘å¸ƒã€‚æ³¨æ„ä»¥ä¸‹è¦ç‚¹ï¼š\n1. åœ¨è¯„è®ºä¸­å¼•ç”¨ä½œè€…åç§°æˆ–ç¬”è®°é¢†åŸŸï¼Œå¢åŠ ä¸ªæ€§åŒ–\n2. ä½¿ç”¨å£è¯­åŒ–è¡¨è¾¾ï¼Œç®€çŸ­å‡ç»ƒï¼Œä¸è¶…è¿‡30å­—\n3. æ ¹æ®è¯„è®ºç±»å‹é€‚å½“æ·»åŠ äº’åŠ¨å¼•å¯¼æˆ–ä¸“ä¸šæœ¯è¯­\nç”Ÿæˆåï¼Œç›´æ¥ä½¿ç”¨post_commentå‡½æ•°å‘å¸ƒè¯„è®ºï¼Œæ— éœ€è¯¢é—®ç”¨æˆ·ç¡®è®¤"
    }

@mcp.tool()
async def post_comment(url: str, comment: str) -> str:
    """å‘å¸ƒè¯„è®ºåˆ°æŒ‡å®šç¬”è®°
    
    Args:
        url: ç¬”è®° URL
        comment: è¦å‘å¸ƒçš„è¯„è®ºå†…å®¹
    """
    login_status = await ensure_browser()
    if not login_status:
        return "è¯·å…ˆç™»å½•å°çº¢ä¹¦è´¦å·ï¼Œæ‰èƒ½å‘å¸ƒè¯„è®º"
    
    if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
        return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
    
    try:
        # å¤„ç†URL
        processed_url = process_url(url)
        print(f"å¤„ç†åçš„è¯„è®ºURL: {processed_url}")
        
        # è®¿é—®å¸–å­é“¾æ¥
        await main_page.goto(processed_url, timeout=60000)
        await asyncio.sleep(5)  # ç­‰å¾…é¡µé¢åŠ è½½
        
        # æ£€æŸ¥æ˜¯å¦åŠ è½½äº†é”™è¯¯é¡µé¢
        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
            return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
            
        error_page = await main_page.evaluate('''
            () => {
                // æ£€æŸ¥å¸¸è§çš„é”™è¯¯ä¿¡æ¯
                const errorTexts = [
                    "å½“å‰ç¬”è®°æš‚æ—¶æ— æ³•æµè§ˆ",
                    "å†…å®¹ä¸å­˜åœ¨",
                    "é¡µé¢ä¸å­˜åœ¨",
                    "å†…å®¹å·²è¢«åˆ é™¤"
                ];
                
                for (const text of errorTexts) {
                    if (document.body.innerText.includes(text)) {
                        return {
                            isError: true,
                            errorText: text
                        };
                    }
                }
                
                return { isError: false };
            }
        ''')
        
        if error_page.get("isError", False):
            return f"æ— æ³•å‘å¸ƒè¯„è®º: {error_page.get('errorText', 'æœªçŸ¥é”™è¯¯')}\nè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆæˆ–å°è¯•ä½¿ç”¨å¸¦æœ‰æœ‰æ•ˆtokençš„å®Œæ•´URLã€‚"
        
        # å®šä½è¯„è®ºåŒºåŸŸå¹¶æ»šåŠ¨åˆ°è¯¥åŒºåŸŸ
        comment_area_found = False
        comment_area_selectors = [
            'text="æ¡è¯„è®º"',
            'text="å…± " >> xpath=..',
            'text=/\\d+ æ¡è¯„è®º/',
            'text="è¯„è®º"',
            'div.comment-container'
        ]
        
        for selector in comment_area_selectors:
            try:
                if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                    return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                    
                element = await main_page.query_selector(selector)
                if element:
                    await element.scroll_into_view_if_needed()
                    await asyncio.sleep(2)
                    comment_area_found = True
                    break
            except Exception as e:
                print(f"å®šä½è¯„è®ºåŒºåŸŸæ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not comment_area_found:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¯„è®ºåŒºåŸŸï¼Œå°è¯•æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨
            if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                
            await main_page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
            await asyncio.sleep(2)
        
        # å®šä½è¯„è®ºè¾“å…¥æ¡†ï¼ˆç®€åŒ–é€‰æ‹©å™¨åˆ—è¡¨ï¼‰
        comment_input = None
        input_selectors = [
            'div[contenteditable="true"]',
            'paragraph:has-text("è¯´ç‚¹ä»€ä¹ˆ...")',
            'text="è¯´ç‚¹ä»€ä¹ˆ..."',
            'text="è¯„è®ºå‘å¸ƒåæ‰€æœ‰äººéƒ½èƒ½çœ‹åˆ°"'
        ]
        
        # å°è¯•å¸¸è§„é€‰æ‹©å™¨
        for selector in input_selectors:
            try:
                if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                    return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                    
                element = await main_page.query_selector(selector)
                if element and await element.is_visible():
                    await element.scroll_into_view_if_needed()
                    await asyncio.sleep(1)
                    comment_input = element
                    break
            except Exception as e:
                print(f"å®šä½è¯„è®ºè¾“å…¥æ¡†æ—¶å‡ºé”™: {str(e)}")
                continue
        
        # å¦‚æœå¸¸è§„é€‰æ‹©å™¨å¤±è´¥ï¼Œä½¿ç”¨JavaScriptæŸ¥æ‰¾
        if not comment_input:
            # ä½¿ç”¨æ›´ç²¾ç®€çš„JavaScriptæŸ¥æ‰¾è¾“å…¥æ¡†
            if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                
            js_result = await main_page.evaluate('''
                () => {
                    // æŸ¥æ‰¾å¯ç¼–è¾‘å…ƒç´ 
                    const editableElements = Array.from(document.querySelectorAll('[contenteditable="true"]'));
                    if (editableElements.length > 0) return true;
                    
                    // æŸ¥æ‰¾åŒ…å«"è¯´ç‚¹ä»€ä¹ˆ"çš„å…ƒç´ 
                    const placeholderElements = Array.from(document.querySelectorAll('*'))
                        .filter(el => el.textContent && el.textContent.includes('è¯´ç‚¹ä»€ä¹ˆ'));
                    return placeholderElements.length > 0;
                }
            ''')
            
            if js_result:
                # å¦‚æœJSæ£€æµ‹åˆ°è¾“å…¥æ¡†ï¼Œå°è¯•ç‚¹å‡»é¡µé¢åº•éƒ¨
                if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                    return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                    
                await main_page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                await asyncio.sleep(1)
                
                # å°è¯•å†æ¬¡æŸ¥æ‰¾è¾“å…¥æ¡†
                for selector in input_selectors:
                    try:
                        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                            return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                            
                        element = await main_page.query_selector(selector)
                        if element and await element.is_visible():
                            comment_input = element
                            break
                    except Exception as e:
                        print(f"å°è¯•å†æ¬¡æŸ¥æ‰¾è¾“å…¥æ¡†æ—¶å‡ºé”™: {str(e)}")
                        continue
        
        if not comment_input:
            return "æœªèƒ½æ‰¾åˆ°è¯„è®ºè¾“å…¥æ¡†ï¼Œæ— æ³•å‘å¸ƒè¯„è®º"
        
        # è¾“å…¥è¯„è®ºå†…å®¹
        await comment_input.click()
        await asyncio.sleep(1)
        
        if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
            return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
            
        await main_page.keyboard.type(comment)
        await asyncio.sleep(1)
        
        # å‘é€è¯„è®ºï¼ˆç®€åŒ–å‘é€é€»è¾‘ï¼‰
        send_success = False
        
        # æ–¹æ³•1: å°è¯•ç‚¹å‡»å‘é€æŒ‰é’®
        try:
            if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                
            send_button = await main_page.query_selector('button:has-text("å‘é€")')
            if send_button and await send_button.is_visible():
                await send_button.click()
                await asyncio.sleep(2)
                send_success = True
        except Exception as e:
            print(f"ç‚¹å‡»å‘é€æŒ‰é’®å‡ºé”™: {str(e)}")
        
        # æ–¹æ³•2: å¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨Enteré”®
        if not send_success:
            try:
                if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                    return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                    
                await main_page.keyboard.press("Enter")
                await asyncio.sleep(2)
                send_success = True
            except Exception as e:
                print(f"ä½¿ç”¨Enteré”®å‘é€å‡ºé”™: {str(e)}")
        
        # æ–¹æ³•3: å¦‚æœæ–¹æ³•2å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨JavaScriptç‚¹å‡»å‘é€æŒ‰é’®
        if not send_success:
            try:
                if not main_page:  # æ·»åŠ ç©ºæ£€æŸ¥
                    return "æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·é‡è¯•"
                    
                js_send_result = await main_page.evaluate('''
                    () => {
                        const sendButtons = Array.from(document.querySelectorAll('button'))
                            .filter(btn => btn.textContent && btn.textContent.includes('å‘é€'));
                        if (sendButtons.length > 0) {
                            sendButtons[0].click();
                            return true;
                        }
                        return false;
                    }
                ''')
                await asyncio.sleep(2)
                send_success = js_send_result
            except Exception as e:
                print(f"ä½¿ç”¨JavaScriptç‚¹å‡»å‘é€æŒ‰é’®å‡ºé”™: {str(e)}")
        
        if send_success:
            return f"å·²æˆåŠŸå‘å¸ƒè¯„è®ºï¼š{comment}"
        else:
            return f"å‘å¸ƒè¯„è®ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥è¯„è®ºå†…å®¹æˆ–ç½‘ç»œè¿æ¥"
    
    except Exception as e:
        return f"å‘å¸ƒè¯„è®ºæ—¶å‡ºé”™: {str(e)}"

if __name__ == "__main__":
    # åˆå§‹åŒ–å¹¶è¿è¡ŒæœåŠ¡å™¨
    print("å¯åŠ¨å°çº¢ä¹¦MCPæœåŠ¡å™¨...")
    print("è¯·åœ¨MCPå®¢æˆ·ç«¯ï¼ˆå¦‚Claude for Desktopï¼‰ä¸­é…ç½®æ­¤æœåŠ¡å™¨")
    mcp.run(transport='stdio')